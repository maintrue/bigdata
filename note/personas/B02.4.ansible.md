# 集群搭建

* 目标
  * 能够通过自动化脚本部署一个集群
* 步骤
  1. 为企业设计一个规模合适的集群
  2. 企业中部署和管理集群的工具
  3. 自动创建虚拟机
  4. 自动化部署服务
    
## 4. 自动化部署服务 (了解, 运维领域)



* 目标
  * 能够通过自动化脚本安装 CM 服务
* 步骤
  1. 痛点和 Ansible
  2. 使用 Vagrant 整合 Ansible
  3. 离线安装 Ansible



### 4.1. 痛点和 Ansible



好了, 我们现在要开始安装 CM 服务了, 大概有如下步骤



1. 配置好每一台机器的系统环境
   1. 修改主机名
   2. 关闭防火墙
   3. 关闭 SELinux
   4. 安装 JDK
   5. 安装 MySQL
   6. ... 一上午过去了
2. 在每一台机器上安装 SCM Agents
   1. Master 01 上下载 Agents
   2. Worker 01上下载 Agents
   3. Worker 02 上下载 Angents
   4. 配置 Master 01
   5. 配置 Worker 01
   6. 配置 Worker 02
   7. 启动 Maser 01 的 Agents
   8. ... 一小时又过去了, 逐渐恼怒 😡
3. 在 Master 01 上安装 SCM
   1. 创建 Linux 用户, hadoop, hive, yarn, hdfs, oozie 等所有服务都要有一个系统用户
   2. 创建 MySQL 用户, 大概六七个
   3. 安装 SCM
   4. 启动
   5. 报错
   6. ... 一下午过去了, 老子不学习! 😡😡

4. 安装 CDH ...



**好了, 这些痛点我们都懂, 于是引入 Ansible, Ansible 非常重要, 几乎是运维领域的银弹, 但是如果大家不打算在运维领域发展, 了解即可, Ansible 可以帮助我们做如下事情**



* 上述所有步骤, Ansible 可以帮助我们以配置的形式编写
* Ansible 可以帮助我们在多台机器上执行配置文件表示的过程



**Ansible 有如下概念**



| 名称      | 解释                                                         |
| :-------- | :----------------------------------------------------------- |
| Playbook  | 剧本, 是 Ansible 中的总控, 根配置文件<br>比如说这次运行 Ansible 的最终任务是搭建好一个 CM 集群, 那我们应该就有一个 Playbook 叫做 `cm_playbook.yml` |
| Roles     | Ansible 任务中的角色<br>例如为了完成 CM 集群的搭建, 可能要配置操作系统, 那应该就把配置操作系统所需要执行的所有配置都放在一个叫做 `system_common` 的 Roles 中 |
| Inventory | Ansible 中的服务器地址配置<br>Ansible 需要在多个主机中执行任务, Inventory 的作用就是告诉 Ansible 主机的地址等信息 |



**首先来看看 PlayBook**



```yml
- name: Create hosts file in locally
  hosts: 192.168.56.101
  any_errors_fatal: True
  become: yes
  roles:
    - hosts

- name: Set yum locally
  hosts: cdh_cluster
  any_errors_fatal: True
  become: yes
  roles:
    - yum_locally
```


* name：描述
* host：主机
* any_errors_fatal：是否报错终止执行
* become：是否使用root用户
* roles：执行的角色  
* 在 `192.168.56.101` 中配置 hosts 文件
* 在 `cdh_cluster` 所对应的机器中配置本地 Yum 仓库

* `cdh_cluster` 是一个分组, 这个分组在 `Inventory` 中配置
* `hosts` 和 `yum_locally` 就是角色



**然后再来看看 Roles yum_locally**



```yml
- name: Set yum repo locally
  yum_repository:
    name: itcast-locally
    description: Local yum repo
    baseurl: http://master01/
    failovermethod: priority
    file: itcast
    priority: 1
    gpgcheck: no
    enabled: yes

- name: Clean yum meata
  command: yum clean all

```



* 第一个任务是通过 Ansible 提供的 Yum repository 插件, 配置本地 Yum 仓库
* 第二个任务是执行一个命令 `yum clean all` 清理 Yum 缓存



### 4.2. 使用 Vagrant 整合 Ansible



Ansible 是一个非常知名的自动化运维工具, 不仅仅只是为了搭建测试环境, 在测试环境和正式环境中, 其应用都很广泛, **先来看看在正式环境中该如何使用 Ansible**



1. 在 13 台机器中, 选择一台作为主控
2. 在主控机器中放入 Ansible 脚本
3. 执行命令运行 Ansible, Ansible 会在 Playbook 中标示的机器上运行



```shell
ansible-playbook --inventory-file=/vagrant/inventory -v /vagrant/playbooks/cdh_cm.yml
```



明白了如何在正式环境使用 Ansible 以后, 使用 Vagrant 搭建测试环境的时候也可以使用 Ansible 脚本, Vagrant 提供了对应的 Provision



1. 编写 Ansible playbook, 文件名为 `testing.yml`

   ```yml
   - hosts: worker_servers
     tasks:
       debug:
         msg: "Hello from {{ inventory_hostname }}"
   ```

   

2. 编写 Inventory, 文件名为 `inventory`

   ```text
   [master_servers]
   master01 ansible_host=192.168.56.101 ansible_user=vagrant ansible_ssh_pass=vagrant
   
   [worker_servers]
   worker01 ansible_host=192.168.56.102 ansible_user=vagrant ansible_ssh_pass=vagrant
   worker02 ansible_host=192.168.56.103 ansible_user=vagrant ansible_ssh_pass=vagrant
   ```

   

3. 编写 Vagrantfile

   ```ruby
   Vagrant.configure("2") do |config|
       config.ssh.password = "vagrant"
   
       config.vm.define "master01" do |master01|
           master01.vm.box = './pkgs/package.box'
           master01.disksize.size = '50GB'    
           master01.vm.network 'private_network', ip: '192.168.56.101'
           master01.vm.hostname = 'master01'
   
           master01.vm.provider 'virtualbox' do |vb|
               vb.gui = false
               vb.name = 'master01'
               vb.memory = 6000
               vb.cpus = 1
               vb.customize ["modifyvm", :id, "--cpuexecutioncap", "50"]
           end
       end
   
       config.vm.define "worker01" do |worker01|
           worker01.vm.box = './pkgs/package.box'
           worker01.disksize.size = '50GB'    
           worker01.vm.network 'private_network', ip: '192.168.56.102'
           worker01.vm.hostname = 'worker01'
   
           worker01.vm.provider 'virtualbox' do |vb|
               vb.gui = false
               vb.name = 'worker01'
               vb.memory = 2048
               vb.cpus = 1
               vb.customize ["modifyvm", :id, "--cpuexecutioncap", "50"]
           end
       end
   
       config.vm.define "worker02" do |worker02|
           worker02.vm.box = './pkgs/package.box'
           worker02.disksize.size = '50GB'    
           worker02.vm.network 'private_network', ip: '192.168.56.103'
           worker02.vm.hostname = 'worker02'
   
           worker02.vm.provider 'virtualbox' do |vb|
               vb.gui = false
               vb.name = 'worker02'
               vb.memory = 2048
               vb.cpus = 1
               vb.customize ["modifyvm", :id, "--cpuexecutioncap", "50"]
           end
       end
   
       config.vm.define "edge" do |edge|
           edge.vm.box = './pkgs/package.box'
           edge.disksize.size = '50GB'    
           edge.vm.network 'private_network', ip: '192.168.56.104'
           edge.vm.hostname = 'edge'
   
           edge.vm.provider 'virtualbox' do |vb|
               vb.gui = false
               vb.name = 'edge'
               vb.memory = 1024
               vb.cpus = 1
               vb.customize ["modifyvm", :id, "--cpuexecutioncap", "50"]
           end
   
           machine.vm.provision :ansible_local do |ansible|
               ansible.playbook       = "testing.yml"
               ansible.verbose        = true
               ansible.install        = true
               ansible.limit          = "all" # or only "nodes" group, etc.
               ansible.inventory_path = "inventory"
           end
       end
   end
   ```

   

4. 运行查看结果



当然, 我们也可以使用 Roles 来封装一下这个任务



1. 创建 `roles/hello/tasks` 目录

2. 编写 Roles

   ```yml
   - name: Hello
   	debug:
   		msg: "Hello from {{ inventory_hostname }}"
   ```

   

3. 修改 Playbook

   ```yml
   - hosts: worker_servers
     roles:
     	- hello
   ```

   

### 4.3. 使用 Ansible 部署 CM



脚本已经为大家编写好了, 因为大家只需要了解这个东西, 所以, 不再深入去讲, 大家有兴趣可以自行研究



1. 离线安装 Ansible
2. 配置 Hosts
3. 配置离线 Yum
4. 离线安装 MySQL
5. ...



### 4.4. 已知问题



#### 可以解决的问题



* 如果在部署过程中, 出现 scm 或者 scm agents 开头的错误, 可以用如下的方式解决
  1. 注释掉 cdh_cm.yml 中的前半部分代码, 在 `Install cloudera agents` 之前的代码都注释掉
  2. vagrant ssh master01
     * 密码是 vagrant
  3. `PYTHONUNBUFFERED=1 ANSIBLE_FORCE_COLOR=true ansible-playbook --limit="all" --inventory-file=/vagrant/inventory -v /vagrant/playbooks/cdh_cm.yml`



* 成功的表现

  * `Save import command id` 开头的命令执行完成, 则意味着整个集群已经部署成功

  * 接下来, 查看进度即可

    1. 打开 `http://master01:7180`

    2. 登录, 账号密码都是 admin

    3. 点击右上角1的小图标, 查看集群部署情况

       ![1582538805661](assets/1582538805661.png)



* Namenode 可能格式化超时, 这是因为集群资源不够, 需要登录到 Master01 上删除 `/dfs/nn`, 然后重试

  <img src="assets/image-20200221110159008.png" alt="image-20200221110159008" style="zoom:50%;" />

* Hive 的 Metastore 和 Oozie 的数据库可能连接超时, 也是因为集群资源不够, 重试即可

  <img src="assets/image-20200221110234199.png" alt="image-20200221110234199" style="zoom:50%;" />

* Hive 的 Schema 有可能创建失败, 同样因为集群无法并行太多任务的原因, 登入到 master01 中, 执行如下步骤

  * ![1582542339828](assets/1582542339828.png)

  1. 登入 MySQL, 删除 metastore 下所有表, `mysql -uhive -ppassword`

     ```sql
     DROP TABLE IF EXISTS BUCKETING_COLS;
     DROP TABLE IF EXISTS CDS;
     DROP TABLE IF EXISTS COLUMNS_V2;
     DROP TABLE IF EXISTS DATABASE_PARAMS;
     DROP TABLE IF EXISTS DBS;
     DROP TABLE IF EXISTS DB_PRIVS;
     DROP TABLE IF EXISTS DELEGATION_TOKENS;
     DROP TABLE IF EXISTS FUNCS;
     DROP TABLE IF EXISTS GLOBAL_PRIVS;
     DROP TABLE IF EXISTS IDXS;
     DROP TABLE IF EXISTS INDEX_PARAMS;
     DROP TABLE IF EXISTS MASTER_KEYS;
     DROP TABLE IF EXISTS NUCLEUS_TABLES;
     DROP TABLE IF EXISTS PARTITIONS;
     DROP TABLE IF EXISTS PARTITION_EVENTS;
     DROP TABLE IF EXISTS PARTITION_KEYS;
     DROP TABLE IF EXISTS PARTITION_KEY_VALS;
     DROP TABLE IF EXISTS PARTITION_PARAMS;
     DROP TABLE IF EXISTS PART_COL_PRIVS;
     DROP TABLE IF EXISTS PART_COL_STATS;
     DROP TABLE IF EXISTS PART_PRIVS;
     DROP TABLE IF EXISTS ROLES;
     DROP TABLE IF EXISTS ROLE_MAP;
     DROP TABLE IF EXISTS SDS;
     DROP TABLE IF EXISTS SD_PARAMS;
     DROP TABLE IF EXISTS SEQUENCE_TABLE;
     DROP TABLE IF EXISTS SERDES;
     DROP TABLE IF EXISTS SERDE_PARAMS;
     DROP TABLE IF EXISTS SKEWED_COL_NAMES;
     DROP TABLE IF EXISTS SKEWED_COL_VALUE_LOC_MAP;
     DROP TABLE IF EXISTS SKEWED_STRING_LIST;
     DROP TABLE IF EXISTS SKEWED_STRING_LIST_VALUES;
     DROP TABLE IF EXISTS SKEWED_VALUES;
     DROP TABLE IF EXISTS SORT_COLS;
     DROP TABLE IF EXISTS TABLE_PARAMS;
     DROP TABLE IF EXISTS TAB_COL_STATS;
     DROP TABLE IF EXISTS TBLS;
     DROP TABLE IF EXISTS TBL_COL_PRIVS;
     DROP TABLE IF EXISTS TBL_PRIVS;
     DROP TABLE IF EXISTS TYPES;
     DROP TABLE IF EXISTS TYPE_FIELDS;
     DROP TABLE IF EXISTS VERSION;
     ```

  2. 在 `/opt/cloudera/parcels/CDH/lib/hive/conf/hive-site.xml` 中加入如下

```xml
<property>
<name>javax.jdo.option.ConnectionUserName</name>
<value>hive</value>
</property>

<property>
<name>javax.jdo.option.ConnectionPassword</name>
<value>hive_password</value>
</property>

<property>
<name>javax.jdo.option.ConnectionURL</name>
<value>jdbc:mysql://master01:3306/metastore?useUnicode=true&amp;characterEncoding=UTF-8</value>
</property>

<property>
<name>javax.jdo.option.ConnectionDriverName</name>
<value>com.mysql.jdbc.Driver</value>
</property>
```

  3. 执行任务初始化 Hive metastore

     ```shell
     /opt/cloudera/parcels/CDH/lib/hive/bin/schematool -dbType mysql -initSchema
     ```

     

* Ansible 执行可能在最后一步失败, 这是因为导入 CDH 集群是一件耗时的工作, 重试的时间不够, 这个问题无需理会, 登录 `master01:7180` 查看集群状态即可, 默认账号和密码都是 `admin`

  <img src="assets/image-20200221110413369.png" alt="image-20200221110413369" style="zoom: 50%;" />



**如果实在是机器的资源有限, 运行速度很慢, 或者无法执行 Yarn 任务, 有以下两种做法**



* 关闭 SCM 有关服务, 只留下 Hadoop 相关服务

  ```shell
  systemctl stop cloudera-scm-agent
  systemctl stop cloudera-scm-server
  ```

  

* 关闭 Edge 机

  ```shell
  vagrant destroy edge
  ```

  

#### 无法解决的问题



* 因为 Master 的内存配置过低, 所以 Hue 的运行受限, 有可能在上传大文件时, 访问 Oozie 时, 会出现无响应
* 因为集群整体资源受限, 所以执行 Oozie 任务时, 可能会出现无法调度的问题



这些问题其实并不是问题, 当给集群足够资源时, 自然会解决, 如果有 32G 的内存, 建议如下分配



* Master 01 分配 12 G
* Workers 分配 8 G