# 1 用户画像的计算框架选型
目标:
- 理解用户画像项目的几种实现方式

步骤:
1. 计算方式
2. 存储方式

## 1.1 离线数仓
目标:
- 回顾离线数仓表结构

步骤:
1. 需求介绍
2. 技术演进
3. 总结

### 1.1.1 需求介绍
**1.需求介绍**
* 有一家公司做收银系统

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200209225808.png[]


* 有一个需求是要统计 每个城市的店铺 每个月销售额 的走向

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200209231145.png[width=600]

**2.业务分析**
* 统计关系: 店铺每个月的销售额, 按照城市区分
* 店铺信息在店铺表中
* 城市信息在收货地址表中
* 订单时间在订单表中
* 店铺表和城市表和订单表关联

**3.业务表**

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200209231535.png[]

### 1.1.2 技术演进
**1.直接在 MySQL 上查询**
1. 查询时会应用线上业务运行
2. 查询语句过于繁琐, 并且多个分析之间是有共性的, 中间层没有保存
3. 用于业务数据库的模型一般特别细节, 分析不方便

**2.维度建模**
* 解决问题 2, 维度建模
1. ODS, 贴源层, 做数据的存储, 当出现问题的时候不再二次抽取
2. DW,  数仓层, 维度建模, 简化查询
3. DM,  集市层, 小型数仓, 为每个部分服务
4. ADS, 应用层, 对应数据应用的需求, 例如便于报表访问等

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200209231535.png[]


* 解决问题 3, 拉宽

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200209232303.png[]

* 表结构
    * ODS
        * 订单表
        * 订单明细表
        * 用户表
        * 店铺表
        * 收货地址表
    * DW
        * 订单事实表
        * 用户维度表
        * 店铺维度表
        * 地址维度表
        * 时间维度表

**3.架构升级, 解决问题 1**

* 数据抽取

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200209234014.png[]

* 只能在 Hive 上做定制查询, 没办法做即席查询, 报表导出太慢

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200209231145.png[width=600]

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200209234425.png[]

### 1.1.3 总结
* 搭建离线数仓的好处
    * 可以保留数据的中间计算, 避免浪费
    * 数据以星型模型维度建模, 方便查询
* 需要理解业务处理过程
    * DW层有: 订单事实, 用户维度, 店铺维度, 商品维度等

## 1.2 实时数仓
目标:
- 回顾实时数仓, 理解实时数仓的架构模式

步骤:
1. 需求介绍
2. 技术演进
3. 总结

### 1.2.1 需求介绍
**1.大屏展示**

例如我们要做一个大屏, 实时的展示当前的业务情况, 其中有一个需求和离线数仓部分的需求类似

* 实时统计 每个区域订单占比

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200210001858.png[]

### 1.2.2 技术演进
**1.直接使用计算工具从 Kafka 中读取数据计算结果**
* 架构

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200210003524.png[]

* 缺陷
    * 计算会特别复杂
    * 没有保留中间计算过程

**2.搭建实时数仓**

* 架构

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200210011407.png[]


* 表结构
  
    总体上来说, 分层的思路和离线数仓是一致的, 大致如下
  
    - ODS, 表以 Kafka Topic 的形式存在于 Kafka 中
        * 订单表
        * 收货地址表
    - DW
        * 订单事实明细, 在 Kafka 中
        * 地区维度信息, 存在于 Redis 中

* 挑战
    * 维度数据如何从 Kafka 中同步到 Redis 中, 或者是否能够使用离线数仓的维度数据?
    * 数据应用不止一种, 很多时候需要对 ADS 进行查询, OLAP 是否支持实时数据的摄入或者插入?
    * 实时系统是不间断运行的, 如何保证高可用?


### 1.2.3 总结
实时数仓和离线数仓的设计思路基本一致

需要理解业务处理过程
* ODS 层全部以 Topic 的形式存在于 Kafka, 其中有 订单 Topic, 收货地址 Topic
* DW 层的事实明细表存在于 Kafka 中, 其中有 订单 Topic
* DW 层的维度信息存在于 Redis 中, 其中有 收货地址信息

## 1.3 离线画像
目标:
- 理解离线的用户画像如何实现

步骤:
1. 需求说明
2. 实现方式一: 使用数仓的方式
3. 实现方式二: 每个标签对应一个 Spark Job
4. 总结

### 1.3.1 需求说明
**1.需求分析**
* 一家电商公司的用户画像, 其中一个标签是客单价
* 客单价有四个级别
    * 1-999
    * 1000-2999
    * 3000-4999
    * 4000-5999

**2.数据源分析**
* 用户表, 取得用户 ID, 相关联的订单数据
* 订单表, 取得订单价格

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200210180646.png[]


**3.目标结果**

| uid | avg_price
| --- | ---
| 10001 | 128
| 10002 | 100
| 10003 | 50


### 1.3.2 实现方式一: 使用数仓的方式
**1.思路**

* 假定数仓已经存在
    * ODS
        * tbl_order, 订单表, 通过外键关联到用户表
        * tbl_user, 用户表
    * DW
        * dw_ord_detail, 订单事实表
        * dw_ord_user, 用户维度表

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200210194042.png[]

* 分析
    1. 关联查询订单和用户
    2. 按照用户分组
    3. 求得每一个用户组的所有订单加个均值

**2.实现**
```sql 
SELECT 
    u.id AS uid, avg(amount) AS avg_price 
FROM dw_ord_detail o JOIN dw_ord_user u 
    ON o.buyer_id = u.id GROUP BY o.buyer_id
```

**3.再加一个标签**
* 需求: 单笔最高 标签
* SQL
``` 
SELECT 
    u.id AS uid, 
    avg(amount) AS avg_price,
    max(amount) AS max_price
FROM dw_ord_detail o JOIN dw_ord_user u 
    ON o.buyer_id = u.id GROUP BY o.buyer_id
```
**4.再加一个**
* 需求: 性别 标签
* SQL
```
SELECT 
    u.id AS uid, 
    avg(amount) AS avg_price,
    max(amount) AS max_price,
    u.gender AS gender
FROM dw_ord_detail o JOIN dw_ord_user u 
    ON o.buyer_id = u.id GROUP BY o.buyer_id
```

**5.总结**

在 Hive 上做用户画像有一些固定的套路

* 从哪里取数据?
    * ODS 层
    * DW 层
* 如何计算?
    * 使用 SQL, 加一个标签, 就加一个标签的查询


**6.但是, 当标签复杂了以后...**

比如说有两个标签
* 客单价, 对用户所有的订单进行统计, 求得平均价格
* 当月购买频次, 对用户当月的订单进行统计, 求得次数

这两个标签的统计范式是不一样的, 这样的 SQl 写起来就比较复杂了, 一般有两种写法
* 使用窗口函数, 比如统计当月的, 就可以开一个窗口来统计
* 使用并集, 比如对不同统计范围的数据分开统计, 最终合并起来
* 使用临时表, 和使用并集的思路一样, 但是是把数据暂存起来

所以, 使用 SQL 固然是简单的, 但是也有一些局限性


### 1.3.3 实现方式二: 每个标签对应一个 Spark Job
**1.分析**
1. 使用 Spark 从 Hive 中的 ODS 或者 DW 取数据
2. 使用 Spark DSL 计算客单价
3. 存入画像表


**2.实现**
``` 
val spark = SparkSession
      .builder()
      .appName("Spark SQL on hive")
      .master("spark://192.168.4.4:7077")
      .config("spark.sql.warehouse.dir", warehouseLocation)
      .enableHiveSupport()
      .getOrCreate()

val source = spark.sql("SELECT u.id AS uid, o.amount AS amount FROM tbl_order o JOIN tbl_user u on o.uid = u.id")
val result = source.select('id, avg('amount))

result.write.xxx.save()
```

可以非常容易的想到, 如果一个标签对应一个 Job 的话, 会有两个好处

* 每个标签独立计算, 每个 Job 都不会很难写
* 每个标签独立计算, 不存在临时表之类的麻烦事, 好管理一些

**3.缺点**

这种方式也有两个很明显的缺点

1. 每个标签独立计算, 会增加很多工作量
2. 每个标签独立计算, 有多少标签就要有多少个 Job, 全量计算的时候, 集群可能会有几百个 Spark job 的负载

问题1 基本上无解, 想少写点代码就必然会写的很复杂, 但是 问题2 可以用以下的办法解决

* 按量设计 Spark Job 的资源占用, 比如说某些任务计算不复杂, 可以少设置一些资源
* 在合理范围内, 尽可能的减少更新, 当然这样会影响画像的准确性
* 多花点钱整个大集群[手动憨笑]


### 1.3.4 总结
* 无论使用 Hive 的方式还是 Spark 的方式, 数据来源都是数仓中的 ODS 层或者 DW 层
* 使用什么方式没有正确答案, 每个公司有自己的选择
    * 使用 Hive 会不好管理, 并且遇到口径和时间范围不同的统计则可能会比较麻烦
    * 使用 Spark 会多占用一些资源, 并且多写点代码
    * 使用 Hive 还有一个很大的问题, 画像一般是需要进行机器学习的处理的, 因为你要挖掘用户的喜好, 基于 Hive 是没办法机器学习的, 需要引入其他的工具, 而 Spark 本身便有机器学习的库

## 1.4 实时画像
实时画像部分不再详细的说了, 有如下几个原因
* 本部分主要说明的是如何处理, 而讲实时更多的是讲架构
* 实时画像和实时数仓的处理流程几乎一致, 所遇到的问题也类似

