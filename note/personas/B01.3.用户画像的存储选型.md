# 1 用户画像的存储选型
目标:
- 理解画像系统如何选择存储系统

步骤:
1. 画像应用的访问特点
2. MySQL 的特点
3. HBase 的特点
4. ES 的特点
5. 总结

## 1.1 画像应用的访问特点
目标:
- 理解画像应用对存储的要求是什么, 从而理解如何选型

步骤:
1. 画像的应用场景
2. 画像对存储的要求
3. 选型

### 1.1.1 画像的应用场景
**1.假设用户画像表如下**

| 用户 ID | 购买品类 | 浏览品类 | 所在商圈
| --- | --- | --- | ---
| 10001 | 男装 | 女装 | 西单
| 10002 | 数码 | 图书 | 东单
| 10003 | 家居 | 家居 | 王府井


**2.分群营销**

例如公司现在新上了一批男装, 希望找到经常购买男装的用户, 发送短信营销, 我应该使用如下的查询方式找到这些用户
``` 
SELECT id FROM up_buying WHERE 购买品类=男装;
```
* 如果有多个查询条件, 这就是一个多字段组合查询

**3.产品优化**

现在要做一个新版本的程序, 上线一个功能是和线下合作的, 为了更精准的定义产品风格, 产品经理想看看我们的用户哪些商圈的比较多

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200211223847.png[width=450]

``` 
SELECT id, 商圈, count(商圈) AS cnt FROM up_loc GROUP BY 所在商圈;
```
* 这是一个统计聚合

### 1.1.2 画像对存储的要求
**1.画像表比较稀疏**
* 一般一个用户画像的项目, 标签至少也是几十上百
* 如果一个画像项目, 有大量用户被打上了所有标签, 这个画像项目是非常不合格的, 质量很差, 所以应该是绝大部分用户都只有一部分标签
* 得出一个规律, 画像表应该很稀疏

**2.多见匹配查找, 例如通过 ID 找用户标签, 通过标签找用户群体**

无论按照标签匹配还是按照 ID 匹配, 都是非常简单的查询, 几乎所有数据都都可满足


**3.多见聚合查询, 例如查看某个标签的占比**

聚合也是一个非常简单的查询方式, 大多数数据库都可以完成


**4.所以, 可以得出画像对存储的要求如下**

* 稀疏表的存储不应占用太多资源, 因为很多数据库即使某个位置没有数据, 也依然会分配存储空间
* 查询种类多样化
  * 按 Key 查询
  * 多条件组合查询
  * 统计聚合
  * 嵌套查询
    
## 1.2 MySQL 的特点
目标:
- 理解 MySQL 最底层的数据结构, 从而理解 MySQL 这个数据库的特点

步骤:
1. B树
2. B+树
3. MySQL 的特性

### 1.2.1 B树

#### 1.2.1.1什么是树

最简单的树肯定当之无愧是二叉树

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212012102.png[width=260]

缺点: 在这棵树里, 似乎想查找某个值不太容易啊


#### 1.2.1.2 查找二叉树

再看看这棵树, 是不是查找就更容易一点了?

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212012319.png[width=260]

#### 1.2.1.3 节点有相对顺序的树的作用
在查找一颗节点之间有顺序的树时, 可以使用类似于折半查找的方式查找, 时间复杂度为 stem:[Log_2N], 这已经是搜索算法的最低时间复杂度了

而数据库中的索引, 就是为了增快查询速度的

综上所述, 数据库中的 **索引** 的数据结构就可以使用类似于查找二叉树这样有相对顺序的树


#### 1.2.1.4 假设每次查找都要读取磁盘, 当查找元素 6 的位置时, 有多少次 IO

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212014325.png[width=350]

由上图可知, 四次

树的高度是多少? 四次

可得知, 每次查找的次数, 是整棵树的高度


#### 1.2.1.5 有一个性能问题
完全二叉树的高度 `h` 和节点个数 `c` 之间的公式是: stem:[c = 2^h - 1]

一千万条数据, 深度大概为 三千层 上下

也就是说, 查找一条数据, 最大可能要 IO 三千次

CPU 执行一条执行的时间大概是 `0.5ns`, 而访问一次机械硬盘的寻址时间大概是 `10ms = 10000ns`, 两万倍, 感受一下这个速度

所幸, 操作系统不会那么傻每次都去读, 而是一次读一个页(`page`), 如果数据在硬盘上存储位置相邻, 则不会有那么多 IO

如何解决这个问题呢? 让层级变少即可


#### 1.2.1.6 B树的结构

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212045019.png[width=400]

如上是一个 `2-3 树`, 是一个 B树 的形式, 含义有两个, 在这里是: "每个节点有两个数据元素, 每个节点有三个子节点, 每个叶子节点有两个数据元素"

无论是什么形式的 B树, 都具备以下定理, 这四个定理也是保证 B树 插入和删除能够平衡的原因

1. 根节点至少两个子节点
2. 每个中间节点都包含 `m` 个孩子, 每个中间节点都包含 `m - 1` 个数据元素
3. **最底层的节点称之为叶子节点**, 所有叶子节点都位于同一层
4. 所有节点中的数据元素按照大小排列, 所有子节点按照数据元素的大小排列, 父节点的数据元素恰好是子节点数据元素的值域划分点

使用伪代码表示每个元素如下
``` 
class BTree[Key, Value] {
val m: Int = 3  // 阶, 节点元素最大个数为树的阶, 例如 2-3树 就是一个 3阶 的树

    /**
     * 节点, 每个节点可以包含多个数据元素和多个子节点
     */
    class Node {
        val maxChildren: Int = m      // 最大节点数
        val maxEntry: Int = m - 1     // 最大数据元素数

        val firstEntry: Entry = null  // 数据元素链表的第一个位置
        val children: List[Node] = List.fill(maxChildren)(null) // 孩子节点
    }

    /**
     * 数据元素
     */
    class Entry {
        val next: Node = null   // 链表中下一个位置

        val key: Key = null     // 用于比较的 Key
        val value: Value = null // 值 Value
    }
}
```

#### 1.2.1.7 B树的查找

按照定理 4, 查找也类似于折半, 比如说查找 5

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212045225.png[width=400]

值得注意一点的是: B树 的查找, 其时间复杂度并不比等量的二叉树小


#### 1.2.1.8 B树 插入的规则
如果当前节点未满, 插入

如果当前节点已满, 分裂节点, 中间大小的值提升, 直到插入根节点

如果根节点也已满, 插入节点成为新的根节点, 层级 +1

#### 1.2.1.9 B树的插入

比如说我要插入一个节点 `4`, 流程如下

1. 从 root 向下查找, 找到 `4` 的位置

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212045410.png[width=400]

2. 当前节点 `3,5` 已满, 按照规则, 需要把节点 `3,5` 拆开, 并且 `4` 向上提升

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212045908.png[width=400]

3. 当前节点 `2,6` 已满, 按照规则, 节点 `2,6` 也需要拆开, 并且 `4` 再次向上提升

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212050306.png[width=400]

4. 刚好根节点未满, 插入根节点

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212050356.png[width=400]

### 1.2.2 B+树

#### 1.2.2.1 B树的问题 1 - 性能不稳定
1.原因

因为 B树 中所有节点都可携带数据元素, 所以导致性能不稳定, 例如

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212045019.png[width=400]

* 查找 Key 为 6 的数据, 在第二层找到, IO 两次
* 查找 Key 为 1 的数据, 在第三层找到, IO 三次


2.解决方案1

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212152320.png[width=400]

* 除了叶子节点以外, 其它节点不再携带数据元素, 这样所有的查找都会落到叶子节点上
* 这样会导致一个新的问题
  * 外部向 BTree 中添加元素的时候是给定 Key 和 Value 添加的
    ``` 
    class BTree[Key, Value] {
    ...
    
        def insert(key: Key, value: Value) = {
    
        }
    }
    ```
  * 也就是说, 如果中间节点不再携带数据元素就要自己生成了, 如何生成?


3.解决方案2

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212153743.png[width=400]

* 让叶子节点包含父节点
* 这样叶子节点就包含了所有数据元素, 而中间节点则只有一个作用, 就是划分叶子节点的值域
  
NOTE: 遗留问题: 中间节点不再携带数据, 则无法查找, 需要自己生成

#### 1.2.2.2 B树 的问题 2 - 范围查找效率太低
1.原因

在 B树 中, 查找一个范围的话, 需要使用树的中序查找, 例如在树中查找 `select ... from ... where x >= 3 and x <= 11`, 大概的步骤有 9步, 如下

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212155745.png[width=400]

2.解决方案

* 在 问题1 的解决方案基础之上, 让叶子节点成为一张链表

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212154831.png[width=400]

* 这样再执行 `select ... from ... where x >= 3 and x <= 11` 时候, 步骤变为 8步, 并且范围涉及的中间越多, 差距就越明显

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212155528.png[width=400]


#### 1.2.2.3 这样的树, 我们称之为 B+树

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212160052.png[width=400]

1.B+树的特性
* 有 k 个子树的中间节点, 就可以存放 K 个数据元素(比 B树 多一个)
* 中间节点不保存数据, 只用来索引, 划分子树值域, 所有数据元素都以卫星的形式和叶子节点关联
* 叶子节点本身按照 Key 有序
* 所有中间节点的元素都存在于子节点


2.B+树的优点

* 单一节点存储更多的元素, IO 次数变少
* 所有查询都要查找到叶子节点, 看起来每次都是都是最差情况, 但是三层的 B+树 可以存放一百万条数据, 通常 B+树 都很低很宽
* 所有叶子节点是形成有序链表, 范围查询性能极强

#### 1.2.2.4 B+树 和 MySQL 的关系
1.从存储的脚上来看, 索引的类型

* 聚集索引

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212164520.png[width=400]

* 非聚集索引

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212164737.png[width=400]


2.MySQL的索引类型

在 MySQL 中, 有两个引擎, 如下
* MyISAM, 早期的引擎, 事务支持很差, 极少使用
* InnoDB, 优化的引擎, 事务支持完备, 最为多见

InnoDB 有如下特点
* 任何一张表的数据都自带一个聚集索引
* 默认情况下, 建表必须有主键, 默认的聚集索引以主键为 Key


3.B+树 和 MySQL 的关系

无论是否聚集, MySQL 中的索引通通都是 B+树 结构

### 1.2.3 MySQL 的特性
随着数据的增多, 插入性能递减
- 根据 B+树 的特性可以知道, 每次在插入的时候都比较复杂, 当数据量增多的时候, 性能衰减会非常明显

查找延迟低
- B+树 是查找树, 其节点之间是有序的, 当需要搜索的时候, 时间复杂度和折半查找一样, 只有 stem:[Log_2N]

范围查询优势明显, 可以实现复杂的查询
- B+树 的叶子节点构成了一个类似链表的结构, 所以进行范围查找的时候, 不需要回到父节点, 可以直接在子节点中进行, 所以在进行一些复杂查询的时候比较方便范围取数据


完整存储所有数据
- 因为 MySQL 的主要目的是 OLTP, OLTP 更强调每次操作一条或者多条数据, 所以 MySQL 是行存储的形式, 行存储为了对齐所有的列, 即使某列为 Null, 也依然会有按照数据类型的占位

## 1.3 HBase 的特点
目标:
- 通过 HBase 的核心数据结构, 理解 HBase 的特点

步骤:
1. MySQL 的问题
2. LSM Tree
3. HBase 的特点

### 1.3.1 MySQL 的问题

#### 1.3.1.1 插入性能会随着树的复杂度而递减

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200212160052.png[width=400]

如果数据太多, 是不是这个树会非常宽, 甚至有几千万的量, 这个树就不只三层了

这个时候插入一条数据的话, 要不断的对比, 导致复杂度升高

所以随着数据量的增大, 这棵树的插入性能会下降

#### 1.3.1.2 行存储

| id | name | school | age
| --- | --- | --- | --- 
| 1 | 张三 | MIT | 10
| 2 | 李四 | null | 10
| 3 | 王五 | 清华 | null

如上, 有一些行中有空值

但是 Schema 已经定义了, 对应的列是有数据类型的, 为了对齐, 所以即使这个地方没有数据, 也依然需要占用对应数据类型的空间

### 1.3.2 LSM Tree

#### 1.3.2.1 解决问题: 插入效率低
多颗小树

不写磁盘, 内存效率更高

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213003534.png[width=400]


#### 1.3.2.2 新的问题: 内存不持久
把数分级

一级存盘, 一级内存

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213004847.png[width=600]

#### 1.3.2.3 新的问题: 不能内存和磁盘数据不同步呀
使用查找树, 这样树的节点之间是有序的

两颗有序的树可以使用归并排序, 时间复杂度很低

这个过程叫做 Flush, Level 0 级别的树达到容量阈值的时候, Flush 到 Level 1 的树

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213011528.png[width=600]

#### 1.3.2.4 归并排序

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213010712.png[width=300]


#### 1.3.2.5 新的问题: 如果数据量太大, 即使是归并, 也是需要耗时的, 还能不能进一步快?
内存大小毕竟有限, 阈值可能比较小, 所以刷新到磁盘中是经常发生的事情

如果一次性把整棵树先刷新到磁盘, 在特定的时间合并这些小树, 就可以进一步的提升速度

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213011825.png[width=800]

#### 1.3.2.6 这个朴素的思想, 就叫做 LSM Tree, 日志合并树

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213012423.png[width=500]

数据的结构为 B树 比较多见, 但是不同的数据库有不同的实现, HBase 中每一颗小树都类似于 B树

插入性能及其优良, 大概比 B+树 快几十倍

查询性能比较差, 因为要扫描三个级别的存储, 比 B+树 要慢几十倍

### 1.3.3 HBase 的特点

#### 1.3.3.1 HBase 和 LSM 树
HBase 的一个表有多个 Region 分布在多个 RegionServer 上, 一个 RegionServer 有多个 Region

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213031242.png[width=500]

每个 Region 又分为 Memstore 和 DiskStore, 其实就是 LSM树

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213031445.png[width=500]

HBase 的存储结构是 Key-Value

- 虽然 HBase 对外提供的看起来好像一种表, 但其实在 Region 中, 数据以 KV 的形式存在

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213034740.png[width=500]


#### 1.3.3.2 哈希函数
哈希函数
- 哈希函数就是将一个不固定长度的数据转为固定长度的数据的算法, 很多时候也叫做摘要算法

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213023013.png[width=500]


哈希冲突
- 因为一般情况下, 哈希是把长度比较长的数据转为比较短的形式, 所以可能存在多个数据的哈希结果是一样的, 这种现象称之为冲突

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213023241.png[width=500]

比较常见的哈希函数
* MD5, 产生 128位 哈希结果
* SHA1, 产生 160位 哈希结果
* SHA256, 产生 256位 哈希结果

#### 1.3.3.3 布隆过滤器
需求: 在一个非常大的数据集合中, 快速的确认某个元素是否存在?

思路 1: 使用哈希表

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213025525.png[width=500]

问题 1: 虽然查的快了, 但是这个哈希表一定很大

思路 2: 映射为固定长度的位数组

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213030027.png[width==500]

问题 2: 看起来好像会产生大量哈希冲突, 起不到应有的作用**

思路 3: 多次哈希, 这样产生冲突的概率就小多了
* 放入 baidu

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213030201.png[width=500]

* 放入 tencent

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213030250.png[width=500]

思路 3 就是我们所说的布隆过滤器
- 如果希望判断一个值是否在一个很大的数据集中, 可以生成一个很小的布隆过滤器, 然后把要查询的值哈希一次, 代入布隆过滤器
    - 如果对应位置的值为 0, 则这个值一定不存在
    - 如果对应位置为 1, 则这个值有可能存在

#### 1.3.3.4 优化 1 : 使用布隆过滤器提升查询性能
HBase 的 LSM 结构中, Level 2 和 Level 3 都是 HFile
- HFile 是 HBase 自定义的一种文件格式

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213032340.png[width=500]


每个 HFile 都包含一个 布隆过滤器
* 在 HBase 中查找数据时候, 会扫描整张表的所有 Region, 以及 Region 的 Memstore 和 HFile
* 每个 HFile 都包含一个布隆过滤器, 则可以快速的跳过一部分 Region, 提升查找速度

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213032500.png[width=500]


#### 1.3.3.5 优化 2 : HFile 的合并
小合并: Minor Compaction
* 小合并一般发生在 Memstore 刷写为 HFile 时, 达到阈值则产生一次合并, 常见如果刷写的 HFile 太小则合并

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213032833.png[width=500]

全合并, Major Compaction
* 全合并一般周期性发生, 例如 24 小时, 合并期间会导致集群 IO 被大量占用, 影响 HBase 的响应时间

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213033233.png[width=500]


总结

* 对照 LSM树, Memstore 是 Level 0, Memstore 刷写的 HFile 就是 Level 1, Major Compaction 后是 Level 2
* 通过把合并分为两种, 会将 IO 分散在不同的时间片, 让 HBase 的运行更加流畅, 性能也更加好

#### 1.3.3.6 优化 3 : 读优化
一级缓存: BlockCache
* MySQL 的 B+树 并不是把数据直接存放在树中, 而是把数据组成 页(Page) 然后再存入 B+树, MySQL 中最小的数据存储单元是 Page
* HBase 也一样, 其最小的存储单元叫做 Block, Block 会被缓存在 BlockCache 中, 读数据时, 优先从 BlockCache 中读取
* BlockCache 是 RegionServer 级别的
* BlockCache 叫做读缓存, 因为 BlockCache 缓存的数据是读取返回结果给客户端时存入的

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213214539.png[width=500]


二级缓存: 当查找数据时, 会先查内存, 后查磁盘, 然后汇总返回
* 因为写是写在 Memstore 中, 所以从 Memstore 就能立刻读取最新状态
* Memstore 没有的时候, 扫描 HFile, 通过布隆过滤器优化读性能

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213031918.png[width=500]


#### 1.3.3.7 总结
HBase 是 LSM树 的一种开源实现, 类似的还有 LevelDB, RocketDB 等

HBase 无论是批量写还是实时写, 性能都超过 MySQL 不少

HBase 的查询只有一种, 就是扫描, Get 也是扫描的一种特殊情况, 所以 HBase 的查询能力不强

HBase 以 KV 的形式存储数据, 所以如果某一单元数据为 Null 则不存, 所以 HBase 适合存储比较稀疏的表

## 1.4 选型
目标:
- 最终确认选型方案

步骤:
1. 画像类型系统访问特点
2. MySQL 的特点
3. HBase 的特点
4. 选型

### 1.4.1 画像类型系统的访问特点
画像表比较稀疏

多见匹配查找, 例如通过 ID 找用户标签, 通过标签找用户群体

多见聚合查询, 例如查看某个标签的占比

### 1.4.2 MySQL 的特点
随着数据的增多, 插入性能递减

查找延迟低

范围查询优势明显, 可以实现复杂的查询

完整存储所有数据, 不适合稀疏表

### 1.4.3 HBase 的特点
HBase 无论是批量写还是实时写, 性能都超过 MySQL 不少

HBase 的查询只有一种, 就是扫描, Get 也是扫描的一种特殊情况, 所以 HBase 的查询能力不强

HBase 以 KV 的形式存储数据, 所以如果某一单元数据为 Null 则不存, 所以 HBase 适合存储比较稀疏的表

### 1.4.4 ES 的特点
虽然没有单独去说基于 Lucene 的 ElasticSearch 和 Solr, 但是也总结一下他们的特点
* 适合一次索引, 多次搜索的场景, 没有真正的更新能力
* 不如 HBase 的数据存储能力强, 适合只存储索引数据
* 所以一般使用 ES或Solr + HBase 的方式, ES或Solr 做搜索, HBase 做存储和简单查询

### 1.4.5 选型
投票
1. 从存储形式上来看, 选 HBase, HBase 是 KV 型数据库, 是不需要提前预设 Schema 的, 添加新的标签时候比较方便
2. 从使用方式上来看, 选 MySQL 似乎更好, 但是 HBase 也可以, 因为并没有太多复杂查询
3. 从写入方式上来看, 选 HBase, 因为画像的数据一般量也不小, HBase 可以存储海量数据, 而 MySQL 不太适合集群部署
- 最终选择 HBase, 同时可选的方案还有 Hive, ES 等

优化
- 可以看到 HBase 的唯一劣势就是查询能力较差, 所以, 可以选择使用 ES 或者 RowKey 作为 HBase 的二级索引, 这个部分后面还会详细说明

image::https://doc-1256053707.cos.ap-beijing.myqcloud.com/20200213035849.png[width=500]
