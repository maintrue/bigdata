1 Kudu 的应用场景
1.1 现代大数据的应用场景
例如现在要做一个类似物联网的项目, 可能是对某个工厂的生产数据进行分析
1.1.1 项目特点
1.数据量大
有一个非常重大的挑战, 就是这些设备可能很多, 其所产生的事件记录可能也很大, 所以需要对设备进行数据收集和分析的话, 需要使用一些大数据的组件和功能
![image](https://user-images.githubusercontent.com/75486726/177327723-fab683f7-c5eb-47b5-8eb1-ee28f7b49f33.png)


2.流式处理
因为数据是事件, 事件是一个一个来的, 并且如果快速查看结果的话, 必须使用流计算来处理这些数据
3.数据需要存储
最终需要对数据进行统计和分析, 所以数据要先有一个地方存, 后再通过可视化平台去分析和处理

1.1.2 对存储层的要求
这样的一个流计算系统, 需要对数据进行什么样的处理呢?

要能够及时的看到最近的数据, 判断系统是否有异常

要能够扫描历史数据, 从而改进设备和流程

所以对数据存储层就有可能进行如下的操作

逐行插入, 因为数据是一行一行来的, 要想及时看到, 就需要来一行插入一行

低延迟随机读取, 如果想分析某台设备的信息, 就需要在数据集中随机读取某一个设备的事件记录

快速分析和扫描, 数据分析师需要快速的得到结论, 执行一行 SQL 等上十天是不行的
1.2 方案
1.2.1 Spark Streaming 配合 HDFS 存储
总结一下需求

实时处理, Spark Streaming

大数据存储, HDFS

使用 Kafka 过渡数据

但是这样的方案有一个非常重大的问题, 就是速度机器之慢, 因为 HDFS 不擅长存储小文件, 而通过流处理直接写入 HDFS 的话, 会产生非常大量的小文件, 扫描性能十分的差
1.2.2 HDFS + compaction
上面方案的问题是大量小文件的查询是非常低效的, 所以可以将这些小文件压缩合并起来

但是这样的处理方案也有很多问题
一个文件只有不再活跃时才能合并

不能将覆盖的结果放回原来的位置
所以一般在流式系统中进行小文件合并的话, 需要将数据放在一个新的目录中, 让 Hive/Impala 指向新的位置, 再清理老的位置
1.2.3 HBase + HDFS
前面的方案都不够舒服, 主要原因是因为一直在强迫 HDFS 做它并不擅长的事情, 对于实时的数据存储, 谁更适合呢? HBase 好像更合适一些, 虽然 HBase 适合实时的低延迟的数据村醋, 但是对于历史的大规模数据的分析和扫描性能是比较差的, 所以还要结合 HDFS 和 Parquet 来做这件事

因为 HBase 不擅长离线数据分析, 所以在一定的条件触发下, 需要将 HBase 中的数据写入 HDFS 中的 Parquet 文件中, 以便支持离线数据分析, 但是这种方案又会产生新的问题

维护特别复杂, 因为需要在不同的存储间复制数据

难以进行统一的查询, 因为实时数据和离线数据不在同一个地方

这种方案, 也称之为 Lambda, 分为实时层和批处理层, 通过这些这么复杂的方案, 其实想做的就是一件事, 流式数据的存储和快速查询
1.2.4 Kudu
Kudu 声称在扫描性能上, 媲美 HDFS 上的 Parquet. 在随机读写性能上, 媲美 HBase. 所以将存储存替换为 Kudu, 理论上就能解决我们的问题了.

1.3 总结
对于实时流式数据处理, Spark, Flink, Storm 等工具提供了计算上的支持, 但是它们都需要依赖外部的存储系统, 对存储系统的要求会比较高一些, 要满足如下的特点
支持逐行插入

支持更新

低延迟随机读取

快速分析和扫描
2 Kudu 和其它存储工具的对比
2.1 OLAP 和 OLTP
广义来讲, 数据库分为 OLTP 和 OLAP

2.1.1 OLTP
先举个栗子, 在电商网站中, 经常见到一个功能 - "我的订单", 这个功能再查询数据的时候, 是查询的某一个用户的数据, 并不是批量的数据

OLTP 需要做的事情是
快速插入和更新

精确查询
所以 OLTP 并不需要对数据进行大规模的扫描和分析, 所以它的扫描性能并不好, 它主要是用于对响应速度和数据完整性很高的在线服务应用中
2.1.2 OLAP
OLAP 和 OLTP 的场景不同, OLAP 主要服务于分析型应用, 其一般是批量加载数据, 如果出错了, 重新查询即可
2.1.3 总结
OLTP 随机访问能力比较强, 批量扫描比较差

OLAP 擅长大规模批量数据加载, 对于随机访问的能力则比较差

大数据系统中, 往往从 OLTP 数据库中 ETL 放入 OLAP 数据库中, 然后做分析和处理
2.2 行式存储和列式存储
行式和列式是不同的存储方式, 其大致如下

2.2.1 行式存储

行式一般用做于 OLTP, 例如我的订单, 那不仅要看到订单, 还要看到收货地址, 付款信息, 派送信息等, 所以 OLTP 一般是倾向于获取整行所有列的信息

2.2.2 列式存储

而分析平台就不太一样了, 例如分析销售额, 那可能只对销售额这一列感兴趣, 所以按照列存储, 只获取需要的列, 这样能减少数据的读取量
2.4 存储模型
结构
Kudu 的存储模型是有结构的表

OLTP 中代表性的 MySQL, Oracle 模型是有结构的表

HBase 是看起来像是表一样的 Key-Value 型数据, Key 是 RowKey 和列簇的组合, Value 是具体的值

主键
Kudu 采用了 Raft 协议, 所以 Kudu 的表中有唯一主键

关系型数据库也有唯一主键

HBase 的 RowKey 并不是唯一主键

事务支持
Kudu 缺少跨行的 ACID 事务

关系型数据库大多在单机上是可以支持 ACID 事务的
2.5 性能
Kudu 的随机读写速度目标是和 HBase 相似, 但是这个目标建立在使用 SSD 基础之上

Kudu 的批量查询性能目标是比 HDFS 上的 Parquet 慢两倍以内
2.6 硬件需求
Hadoop 的设计理念是尽可能的减少硬件依赖, 使用更廉价的机器, 配置机械硬盘

Kudu 的时代 SSD 已经比较常见了, 能够做更多的磁盘操作和内存操作

Hadoop 不太能发挥比较好的硬件的能力, 而 Kudu 为了大内存和 SSD 而设计, 所以 Kudu 对硬件的需求会更大一些
