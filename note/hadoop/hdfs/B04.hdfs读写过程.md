# 1 hdfs读写过程

## 1.1 HDFS 文件写入过程

1.Client发起文件上传请求, 通过 RPC 与 NameNode建立通讯, NameNode 检查目标文件是否已存在, 父目录是否存在, 返回是否可以上传

2.Client 请求NameNode告知上传的第一个 block 该传输到哪些 DataNode 服务器上

3.NameNode 根据配置文件中指定的备份数量及机架感知原理进行文件分配, 返回可用的
DataNode 的地址如: A, B, C
Hadoop 在设计时考虑到数据的安全与高效, 数据文件默认在HDFS 上存放三份, 存储策略为本地一份, 同机架内其它某一节点上一份, 不同机架的某一节点上一份。

4.Client 请求 3 台 DataNode 中的一台 A 上传数据（本质上是一个 RPC 调用，建立 pipeline
）, A 收到请求会继续调用 B, 然后 B 调用 C, 将整个 pipeline 建立完成, 后逐级返回 client

5.Client 开始往 A 上传第一个 block（先从磁盘读取数据放到一个本地内存缓存）, 以
packet 为单位（默认64K）, A 收到一个 packet 就会传给 B, B 传给 C. A 每传一个 packet 会放入一个应答队列等待应答

6.数据被分割成一个个 packet 数据包在 pipeline 上依次传输, 在 pipeline 反方向上, 逐个发送 ack（命令正确应答）, 最终由 pipeline 中第一个 DataNode 节点 A 将 pipelineack 发送给 Client

7.当一个 block 传输完成之后, Client 再次请求 NameNode 上传第二个 block 到服务 1，从第二步重复直至传输完毕

# 1.2 HDFS 文件读取过程

1.Client向NameNode发起RPC请求，来确定请求文件block所在的位置，nameNode也会做权限检查

2.NameNode会视情况返回文件的部分或者全部block列表，对于每个block，NameNode 都会返回含有该block 副本的DataNode 地址； 这些返回的DataNode 地址，会按照集群拓扑结构得出DataNode 与客户端的距离，然后进行排序，排序两个规则：网络拓扑结构中距离，Client 近的排靠前；心跳机制中超时汇报的DN 状态为STALE，这样的排靠后

3.Client 选取排序靠前的DataNode来读取block，如果客户端本身就是DataNode，那么将从本地直接获取数据(短路读取特性)；

4.底层上本质是建立Socket Stream（FSDataInputStream），重复的调用父类DataInputStream 的read 方法，直到这个块上的数据读取完毕；

5.当读完列表的block 后，若文件读取还没有结束，客户端会继续向NameNode 获取下一批的block 列表；

6.读取完一个block 都会进行checksum 验证，如果读取DataNode 时出现错误，客户端会通知NameNode，然后再从下一个拥有该block 副本的DataNode 继续。

7.read 方法是并行的读取block 信息，不是一块一块的读取；NameNode 只是返回Client请求包含块的DataNode地址，并不是返回请求块的数据；

8.最终读取来所有的block会合并成一个完整的最终文件。