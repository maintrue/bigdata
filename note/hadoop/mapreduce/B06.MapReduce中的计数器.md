# 1 MapReduce 中的计数器
计数器是收集作业统计信息的有效手段之一，用于质量控制或应用级统计。计数器还可辅助诊断系统故障。如果需要将日志信息传输到 map 或 reduce 任务， 更好的方法通常是看能否用一个计数器值来记录某一特定事件的发生。对于大型分布式作业而言，使用计数器更为方便。除了因为获取计数器值比输出日志更方便，还有根据计数器值统计特定事件的发生次数要比分析一堆日志文件容易得多。

## 1.1 hadoop内置计数器列表
| 计数器名称 | 类路径
| --- | --- |
| MapReduce任务计数器      | org.apache.hadoop.mapreduce.TaskCounter |                       
| 文件系统计数器            | org.apache.hadoop.mapreduce.FileSystemCounter |                 
| FilelnputFormat计数器 | org.apache.hadoop.mapreduce.lib.input-FilelnputFormatCounter |   
| FileOutputFormat计数器 | org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter | 
| 作业计数器              | org.apache.hadoop.mapreduce. JobCounter |


每次mapreduce执行完成之后，我们都会看到一些日志记录出来，其中最重要的一些日志记录如下截图

![image](https://user-images.githubusercontent.com/75486726/180607483-654fd919-31d3-4096-922f-e7a4d0b73504.png)

所有的这些都是MapReduce的计数器的功能，既然MapReduce当中有计数器的功能，我们如何实现自己的计数器？？？

# 2 案例
需求：以以上分区代码为案例，统计map接收到的数据记录条数

## 2.1 第一种方式
第一种方式定义计数器，通过context上下文对象可以获取我们的计数器，进行记录 通过context上下文对象，在map端使用计数器进行统计
``` 
public class CounterMapper extends Mapper<LongWritable, Text,Text, NullWritable> {
    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        Counter counter = context.getCounter("MAPPER_COUNT", "MapperCounter");
        counter.increment(1l);
        context.write(value,NullWritable.get());
    }
}
```

## 2.2 第二种方式
通过enum枚举类型来定义计数器 统计reduce端数据的输入的key有多少个
``` 
public class CounterReducer extends Reducer<Text, NullWritable,Text,NullWritable> {
    public static enum Counter{
       MY_REDUCE_COUNTER
   }
    @Override
    protected void reduce(Text key, Iterable<NullWritable> values, Context context) throws IOException, InterruptedException {
        context.getCounter(Counter.MY_REDUCE_COUNTER).increment(1l);
        context.write(key,NullWritable.get());
    }
}
```
