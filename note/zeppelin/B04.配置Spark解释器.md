# 1 配置 Spark 解释器
Zeppelin 只是一个笔记工具, 使用 Zeppelin 来编写 Spark 代码的时候, 依然使用的 Spark 的运行环境, Spark 的运行环境会在一个叫做 Spark 解释器 的进程中运行, 也可以连接 Yarn 来运行 Spark 程序

首先在主界面右上角选中解释器配置

![image](https://user-images.githubusercontent.com/75486726/179739045-da166465-a8e6-45ea-aa85-466561cc52a8.png)


找到 Spark 相关的配置, 进行配置

![image](https://user-images.githubusercontent.com/75486726/179739074-f31ded30-ec48-4752-b074-8b0d634c95c2.png)


将上述标注的参数改为如下样子

![image](https://user-images.githubusercontent.com/75486726/179739098-aca18012-59ea-4e95-86da-eceb159fa9ae.png)


Note 界面
创建一个新的 Note
![image](https://user-images.githubusercontent.com/75486726/179739137-6b5763b6-3d54-445f-8f1d-4760a7a000d3.png)


进入 Note 界面后如下

![image](https://user-images.githubusercontent.com/75486726/179739168-95e65334-d746-40ac-ab86-d05bbd82d77d.png)

笔记是由一个一个的段组成的, 每一个段可以不同类型的, 有的段被当作代码运行, 有的段是 MarkDown 文本
![image](https://user-images.githubusercontent.com/75486726/179739194-5ba8cb31-23aa-4189-b65d-8287ab271151.png)


一个段由三部分组成

代码段

结果段

命令

在代码部分编写代码, 可以是 Spark, Python, SQL, MarkDown 等, 支持什么语言是根据有什么 Interpreter 解释器来决定的, 如果安装了 Spark 解释器, 才可以编写 Spark 的代码

代码段编写过代码以后, 可以通过 Shift + Enter 来运行这段代码, 结果会显式在结果段中, Spark 的代码运行会显式其运行结果, MarkDown 的代码运行会显式其被转为 HTML 的样式

可以通过在第一行以 % 号开头, 指定此段代码的类型
![image](https://user-images.githubusercontent.com/75486726/179739229-54f58a01-5694-44ac-bee3-7a05b4049dba.png)



