
### Kettle整合Hive

####  初始化数据

1、连接hive

| beeline连接hive                  |
| -------------------------------- |
| ![img](assets/clip_image039.jpg) |



2、创建并切换数据库

```sql
create database test;
use test;
```



3、创建表

```sql
create table a(a int,b int)
row format delimited fields terminated by ',' stored as TEXTFILE;
show tables;
```



4、创建数据文件

```shell
vim a.txt
1,11
2,22
3,33
```



5、 从文件加载数据到表

```sql
load data local inpath '/root/a.txt' into table a;
```



6、查询表

```sql
select * from a;
```

#### kettle与Hive整合

1、从虚拟机下载Hadoop的jar包

```shell
sz /export/servers/hadoop-2.6.0-cdh5.14.0/share/hadoop/common/hadoop-common-2.6.0-cdh5.14.0.jar
```

2、把jar包放置在\data-integration\lib目录下

| 上传到lib目录下                                              |
| ------------------------------------------------------------ |
| ![image-20200205170115700](assets/image-20200205170115700.png) |



3、重启kettle，重新加载生效

关掉之前打开的kettle重新启动！！

#### 从hive中读取数据

- hive数据库是通过jdbc来进行连接，可以通过表输入控件来获取数据。

需求：

- 从hive数据库的test库的a表中获取数据，并把数据保存到Excel中。

实现步骤：

1、设计一下kettle组件结构

选择输入文件夹内的表输入组件：

| 表输入组件                                                   |
| ------------------------------------------------------------ |
| ![image-20200205170433530](assets/image-20200205170433530.png) |
| <img src="assets/clip_image047.png" align="left" style="border:1px solid #999"/> |



2、配置表输入组件

| 新建hivejdbc连接：                                           |
| ------------------------------------------------------------ |
| ![image-20200205170958301](assets/image-20200205170958301.png) |
| ![image-20200205171055461](assets/image-20200205171055461.png) |
| 配置excel输出组件                                            |
| ![image-20200205171150064](assets/image-20200205171150064.png) |
| ![image-20200205171210756](assets/image-20200205171210756.png) |



#### 把数据保存到hive数据库

hive数据库是通过jdbc来进行连接，可以通过表输出控件来保存数据。

需求：

- 从Excel资料\02.kettle测试数据\01.用户数据源\file_user.xls中读取数据，把数据保存在hive数据库的test数据库的t_user表。

实现步骤：

1、设计如下kettle组件结构

| 组件配置图                                                   |
| ------------------------------------------------------------ |
| <img src="assets/clip_image054.png" align="left" style="border:1px solid #999"/> |



2、配置 Excel输入组件

| excele输入组件                                               |
| ------------------------------------------------------------ |
| ![image-20200205171342879](assets/image-20200205171342879.png) |
| 查看excel解析字段是否正确                                    |
| ![image-20200205171512191](assets/image-20200205171512191.png) |



2、配置表输出组件

| 表输出组件                                                   |
| ------------------------------------------------------------ |
| ![image-20200227152851902](assets/image-20200227152851902.png) |
| 获取流中的字段                                               |
| ![image-20200205173951319](assets/image-20200205173951319.png) |
| ![image-20200205174959098](assets/image-20200205174959098.png) |
| 验证                                                         |
| ![image-20200205175138955](assets/image-20200205175138955.png) |



#### 执行Hive的HiveSQL语句

Kettle中可以执行Hive的HiveSQL语句，使用作业的SQL脚本。

需求：

- 聚合查询weblogs表（以IP和年月分组统计的PV数据），同时建立一个新表保存查询数据。

**准备hive表**

在hive的test数据库下创建weblogs表：

```sql
 CREATE TABLE `weblogs`(                           
  `client_ip` string,                              
  `full_request_date` string,                      
  `day` string,                                    
  `month` string,                                  
  `month_num` int,                                 
  `year` string,                                   
  `hour` string,                                   
  `minute` string,                                 
  `second` string,                                 
  `timezone` string,                               
  `http_verb` string,                              
  `uri` string,                                    
  `http_status_code` string,                       
  `bytes_returned` string,                         
  `referrer` string,                               
  `user_agent` string) 
  row format delimited fields terminated by '\t' stored as textfile;
```

导入资料\资料\02.kettle测试数据\hive-weblogs\下的数据

```shell
load data local inpath '/root/weblogs_parse.txt' into table weblogs;
```

验证数据

```sql
select * from test.weblogs limit 5;
```



实现步骤：

1、设计如下作业组件结构

| 设计如下作业组件结构                                         |
| ------------------------------------------------------------ |
| ![image-20200205175216309](assets/image-20200205175216309.png) |
| ![image-20200205175313672](assets/image-20200205175313672.png) |
| ![img](assets/clip_image069.png)                             |





2、配置SQL组件

| 配置sql组件                                                  |
| ------------------------------------------------------------ |
| ![image-20200205175421659](assets/image-20200205175421659.png) |
| ![image-20200205175421659](assets/image-20200205175421659.png) |



3、测试数据是否生成

| 验证数据                                                     |
| ------------------------------------------------------------ |
| ![image-20200205175518614](assets/image-20200205175518614.png) |
