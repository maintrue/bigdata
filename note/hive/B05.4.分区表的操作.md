# 1 分区表的操作
在大数据中，最常用的一种思想就是分治，我们可以把大的文件切割划分成一个个的小的文件，这样每次操作一个小的文件就会很容易了，同样的道理，在hive当中也是支持这种思想的，就是我们可以把大的数据，按照每月，或者天进行切分成一个个的小的文件,存放在不同的文件夹。分区就是分目录。

## 1.1 创建分区表

**创建分区表语法**
``` 
create table score(s_id string,c_id string, s_score int) partitioned by (month string) row format delimited fields terminated by '\t';
```
partitioned by 后面加标记字段，和表字段没什么关系，就相当一个目录名称

**创建一个表带多个分区**
多分区就是hdfs多分几个文件夹
``` 
create table score2 (s_id string,c_id string,s_score int) partitioned by (year string,month string,day string) row format delimited fields terminated by '\t';
```

## 1.2 分区表加载数据

**加载数据到分区表中**
``` 
load data local inpath '/export/servers/hivedatas/score.csv' into table score partition (month='201806');
```


**加载数据到多分区表中**
``` 
load data local inpath '/export/servers/hivedatas/score.csv' into table score2 partition(year='2018',month='06',day='01');
```

## 1.3 分区表查询

**多分区表联合查询(使用 union all)**
``` 
select * from score where month = '201806' union all select * from score where month = '201807';
```

## 1.4 分区表管理操作

**查看分区**
``` 
show partitions score;
```

**添加一个分区**
``` 
alter table score add partition(month='201805');
```

**删除分区**
``` 
alter table score drop partition(month = '201806');
```

## 1.5 综合练习

**需求描述**

现在有一个文件score.csv文件，存放在集群的这个目录下/scoredatas/month=201806，这个文件每天都会生成，存放到对应的日期文件夹下面去，文件别人也需要公用，不能移动。需求，创建hive对应的表，并将数据加载到表中，进行数据统计分析，且删除表之后，数据不能删除

**数据准备**
``` 
hdfs dfs -mkdir -p /scoredatas/month=201806
hdfs dfs -put score.csv /scoredatas/month=201806/
```

**创建外部分区表**

创建外部分区表，并指定文件数据存放目录
``` 
create external table score4(s_id string, c_id string,s_score int) partitioned by (month string) row format delimited fields terminated by '\t' location '/scoredatas';
```
进行表的修复( 建立表与数据文件之间的一个关系映射)
``` 
msck repair table score4;
```