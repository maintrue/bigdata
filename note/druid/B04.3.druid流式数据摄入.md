# 1 流式（实时）摄取

## 1。1  Kafka-indexing-service（官方推荐使用）
之前的流式摄取方式realtimenode ，tranquility与kafka-indexing-service对比，该种方式的优势有哪些？

1. realTime node存在单点问题，并且不能有效扩展，官方是不建议生产环境使用的，新版本已经完全弃用。
2. Tranqulity方式：需要启动一个扩展程序改程序从数据源（kafka等）读取数据后推送给druid集群，但是这种方式存在一些弊端，由于其架构设计中存在一个时间窗口的概念，很容易出现数据到来时与窗口不匹配导致数据被丢弃，所以会造成数据丢失，所以官方建议如果使用Tranqulity方式实时摄取数据时需要使用离线数据导入每天修正数据否则可能计算结果有误。
3. Kafka-indexing-service方式：
    1. 引入SuperVisor，用于管理实时任务(peon)的生命周期，包括任务的启动，停止，副本管理，失败任务恢复等
    2. 实时任务主动消费kafka数据，不需要像Tranqulity维护一个推送程序，
    3. 实时任务使用kafka低阶api,自己保存kafka offset，提升了数据的可靠性，
    4. 不丢弃延时数据；

Supervisor就是overlord节点启动的一个线程，该线程负责一个实时摄取任务的完整过程，创建新的任务，以及补足副本数量等，

如何做到不丢弃延迟数据？

一个实时任务不在只是生成一个时间范围的segment,而是根据收到的数据的事件时间来确定自己属于哪个segment,如果所属segment已经创建，则新建一个segment的分片将数据写入该分片中实现延迟数据的追加。

配置文件修改：
```
/export/servers/druid010/conf/druid/_common/common.runtime.properties
druid.extensions.loadList=["druid-kafka-indexing-service",  "druid-datasketches", "mysql-metadata-storage","druid-hdfs-storage"]
```

案例：

```
{
    "type": "kafka",
    "dataSchema": {
        "dataSource": "kafkatest",
        "parser": {
            "type": "string",
            "parseSpec": {
                "format": "json",
                "timestampSpec": {
                    "column": "timestamp",
                    "format": "auto"
                },
                "dimensionsSpec": {
                    "dimensions": [
                        "city",
                        "platform"
                    ]
                }
            }
        },
        "metricsSpec": [
            {
                "name": "count",
                "type": "count"
            },
            {
                "name": "click",
                "type": "longSum",
                "fieldName": "click"
            }
        ],
        "granularitySpec": {
            "type": "uniform",
            "segmentGranularity": "DAY",
            "queryGranularity": "NONE",
            "rollup": false
        }
    },
    "tuningConfig": {
        "type": "kafka",
        "reportParseExceptions": false
    },
    "ioConfig": {
        "topic": "adtest",
        "replicas": 2,
        "taskDuration": "PT10M", // 10分钟生成一个segment
        "completionTimeout": "PT20M",   // 任务超时 抛弃任务
        "consumerProperties": {
            "bootstrap.servers": "hp101:9092,hp102:9092"
        }
    }
}
```



提交kafka索引任务

```
curl -X POST -H 'Content-Type: application/json' -d @kafka_test_index.json http://hp101:8090/druid/indexer/v1/supervisor
```



启动kafka控制台版本生产者

```
 bin/kafka-console-producer.sh --topic adtest --broker-list hp101:9092
```

发送数据：

```
{"timestamp":"1559736155453","city":"beijing","platform":"pc","click":"0"}
```



查询规则文件

```
{
    "queryType":"timeseries",
    "dataSource":"kafkatest",
    "granularity":{"type": "period", "period": "P1D", "timeZone": "Asia/Shanghai"},
    "aggregations":[
        {
            "type":"longSum",
            "name":"click",
            "fieldName":"click"
        },{
            "type":"longSum",
            "name":"pv",
            "fieldName":"count"
        }
    ],
    "intervals":["2018-06-02/2019-06-06"]
}
```

提交查询

```
curl -X 'POST'  -H'Content-Type: application/json'  -d @query-kafkatest.json http://hp103:8082/druid/v2/?pretty
```

