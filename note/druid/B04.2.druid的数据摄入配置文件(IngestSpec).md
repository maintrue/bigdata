# druid数据摄入规则

druid支持批量数据摄入和实时流数据摄入两种数据摄入方式，其中批量数据摄入可以周期性的通过hadoop批量摄入静态数据，实时流数据摄入分为实时节点（streaming pull）,以及indexing-service +tranquility(streaming      push),kafkaIndex-indexing-service;

摄入配置文件概述：

基本属性：

type：表示上传的方式，本地文件上传使用index，hdfs文件上传使用index_hadoop。

druid摄入规则(spec)包含三个重要的属性配置，

"dataSchema"属性定义了数据摄入模式（必须配置项），其中包括数据源名称（‘datasource'),数据解析方式（“parser"),指标计算规则（”metricsSpec"),粒度规则（"granularitySpec");

"ioConfig"属性定义摄入的数据源，比如可以配置'hadoop'批量静态数据摄入；

“tunningConfig"属性定义数据摄入过程中的各种优化配置（可选配置）

首先我们先要分析清楚我们的数据需要划分为时间序列以及维度列还有指标列，划分的标准是：

1：druid中每个数据都必须有一个时间戳，数据是按照时间分片的，每个查询都有一个时间维度的过滤器，查询结果可以通过时间划分，年月日等；

2：维度字段，主要作用是用于过滤条件或者在group by查询时作为分组字段，数据类型一般都是字符串；

3：指标字段，指标字段就是聚合字段，指标字段类型一般是数值类型；

Ingestion Spec 数据摄入完整样例：

```
{
  "type" : "index",
  "spec" : {
    "ioConfig" : {
      "type" : "index",
 "firehose" : {
    "type" : "local",
    "baseDir" : "/data/",
    "filter" : "ad_event.json"
   }    

},
    "dataSchema" : {
      "dataSource" : "ad_event_local",
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "day",
        "queryGranularity" : "hour",
        "intervals" : ["2018-12-01/2018-12-03"]
      },
      "parser" : {
        "type" : "String",
        "parseSpec" : {
          "format" : "json",
          "dimensionsSpec" : {
            "dimensions" : [
              "city",
              "platform"
            ]
          },
          "timestampSpec" : {
            "format" : "auto",
            "column" : "timestamp"
          }
        }
      },
      "metricsSpec" : [
        {
          "name" : "count",
          "type" : "count"
        },
        {
          "name" : "click",
          "type" : "longSum",
          "fieldName" : "click"
        }
      ]
    },
    "tuningConfig" : {
      "type" : "index",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000
      },
      "jobProperties" : {}
    }
  }
}

```



## 数据解析-dataschema

1：数据格式  druid可以加载结构化的数据，包括json,csv,tsv，当然也可以加载自定义的格式，

json格式：

![1558774273992](https://user-images.githubusercontent.com/75486726/178938654-fd0a2d8b-50b4-4a1e-a6c5-7272f0417ad2.png)

csv格式：（按照逗号分隔）

![1558774299906](https://user-images.githubusercontent.com/75486726/178938719-57d46cc4-3596-43b3-84cb-6ed99d98d875.png)

tsv格式（按照tab键分隔）

![1558774358285](https://user-images.githubusercontent.com/75486726/178938764-efa3afe7-7aac-43fa-822d-1cc877061145.png)


### 格式解析--parser

解析器属性也有多种类型，使用最多的就是字符串解析器（默认的解析器），此外还有ProtobufParser;

重点来看StringParser解析器

![1558774517930](https://user-images.githubusercontent.com/75486726/178938822-5f45f163-8891-45c6-adfa-674de1b02106.png)

#### 解析规则-parseSpec

该属性定义了解析规则，解析器通过format属性值确定输入数据格式（常用的格式就是json,csv,tsv);

通过"timestampSpec"属性确定输入数据的时间戳格式以及格式化方法，通过dimensionsSpec属性确定维度列，

##### timestampSpec时间戳规则定义：

![1558774914438](https://user-images.githubusercontent.com/75486726/178938874-0b4c762d-740a-4b3c-9a82-ca05bc71d007.png)

时间戳规则定义样例：

![1558775047914](https://user-images.githubusercontent.com/75486726/178938932-d7c3c2a1-45a8-48f6-94da-7737518bbba0.png)

##### dimensionsSpec 维度规则定义

![1558775727403](https://user-images.githubusercontent.com/75486726/178939001-0aa7c639-ae61-48c2-abd7-53ff480d4e3d.png)

![1558775791129](https://user-images.githubusercontent.com/75486726/178939046-65ea58b0-7429-424a-b7bb-81fd9f33164c.png)

##### JSON格式数据解析规则配置：

![1558776391094](https://user-images.githubusercontent.com/75486726/178939098-bb1cc4a9-aeee-4652-aa56-cddd7701a0b8.png)

JSON格式数据解析规则样例

![1558776424308](https://user-images.githubusercontent.com/75486726/178939130-aeb981ce-df0f-4c44-830b-61e2402d6a44.png)

##### CSV格式数据解析它的规则如下图：

![1558776540786](https://user-images.githubusercontent.com/75486726/178939171-bba15058-b045-416c-8743-ddea71efc82c.png)

由于CSV格式数据不包含列名和表头，解析规则"columns"属性定义数据中包含的所有列名，实际数据中各列对应的值必须和定义的列名顺序相同；

CSV格式数据解析规则样例：

![1558776685952](https://user-images.githubusercontent.com/75486726/178939206-b610209c-10d3-4ce1-83f2-b5034ac322df.png)

### 粒度规则

粒度规则需要我们设置“granularitySpec"属性来定义规则，索引任务根据粒度规则生成Segment,

粒度规则定义如下：

![1558776989030](https://user-images.githubusercontent.com/75486726/178939250-2a38c445-a9ae-4fd2-9dae-9b391be74125.png)

粒度规则定义的样例：

![1558777026926](https://user-images.githubusercontent.com/75486726/178939287-9100f9c7-9224-4eaa-b64b-481e85a10ae1.png)

### 指标列解析-metricsSpec



metricsSpec是一个JSON数组，指明所有的指标列和所使用的聚合函数，数据格式：

```
"metricsSpec" : [
        {
          "name" : "count",
          "type" : "count"
        },
        {
          "name" : "added", #聚合后指标的列名
          "type" : "longSum",#count/longSum等聚合函数类型
          "fieldName" : "added" #聚合函数使用到的原始数据列名
        }
      ]
```

可以使用的聚合函数有：count,longSum,doubleSum,longMin,longMax,doubleMin,doubleMax;关于count我们要重点注意一下，这个行数和初始的摄入行数是不一样的，因为druid会进行原始数据的聚合，这个行数是指的聚合后的行数。

## ioConfig

ioConfig数据源相关配置（基于hadoop批量导入）：

![1558778913054](https://user-images.githubusercontent.com/75486726/178939355-ccdd84dd-7dd7-49ce-854d-7ba8ed85a34d.png)

type本地文件“local”，hdfs使用“hadoop”

inputSpec属性设置执行批量导入任务的数据来源，

static

摄取固定路径下的静态数据，设置规则如下图：

![1558779180286](https://user-images.githubusercontent.com/75486726/178939398-c22f6bc4-c9c9-4f24-b8b6-3156ab99f1c5.png)

摄取静态数据样例：

```
"ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "quickstart/wikiticker-2015-09-12-sampled.json"
      }
    }
```



## tunningConfig

tunningConfig优化配置选项如图：

![1558779604035](https://user-images.githubusercontent.com/75486726/178939443-17860c0b-c25c-4f80-b84e-32d24465b876.png)

优化配置样例：

```
 "tuningConfig" : {
      "type" : "hadoop",
      "partitionsSpec" : {
        "type" : "hashed",
	"targetPartitionSize": 5000000
	}
    }
```

segment的分区

segment通常按照时间戳分区，可以通过分区规则设置进一步分区，在tunningConfig中优化选项的partitionSpec中设置；druid支持两种分区策略：基于哈希的分区和基于单维度的分区，推荐使用哈希分区方式，这种方式能更有助于提高索引性能。

基于哈希的分区

选择一些segment，然后根据这些segment每行所有维度的哈希值进行分区，可配置参数如下：

![1558779921993](https://user-images.githubusercontent.com/75486726/178939494-0a96679e-3e69-4f75-8dfc-4155301fb26e.png)

分区规则的样例：

```
"partitionsSpec" : {
        "type" : "hashed",
	"targetPartitionSize": 5000000
	}
	或者
	"partitionsSpec" : {
        "type" : "hashed",
		"numShards": 5
	}
```

