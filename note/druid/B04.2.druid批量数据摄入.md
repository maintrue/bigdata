# 1 批量（离线）摄取

## 1.1 以索引服务方式摄取

index-service

![1558782367657](https://user-images.githubusercontent.com/75486726/178938458-b7dcad3a-5124-404e-9cf0-84277a9a221f.png)

可以通过index-service的方式批量摄取数据，我们需要向overlord提交一个索引任务，overlord接受任务，通过zk将任务信息分配给middleManger,middlemanager领取任务后创建Peon进程，通过zk向overlord汇报任务状态；

案例:ad_event.json

```
mkdir /data
cd /data
vi ad_event.json

{"timestamp":"2018-12-01T01:03.00Z","city":"beijing","platform":"pc","click":"0"}
{"timestamp":"2018-12-01T01:01.00Z","city":"guangzhou","platform":"pc","click":"1"}
{"timestamp":"2018-12-01T01:03.00Z","city":"beijing","platform":"pc","click":"0"}
{"timestamp":"2018-12-01T05:01.00Z","city":"beijing","platform":"pc","click":"1"}
{"timestamp":"2018-12-01T01:03.00Z","city":"guangzhou","platform":"pc","click":"0"}
{"timestamp":"2018-12-01T01:01.00Z","city":"beijing","platform":"mobile","click":"0"}
```

本地批量索引任务规则文件

```
cd /export/servers/druid/quickstart
mkdir job
cd job
vi index-local.json

{
    "type": "index",
    "spec": {
        "ioConfig": {
            "type": "index",
            "firehose": {
                "type": "local",
                "baseDir": "/data/",
                "filter": "ad_event.json"
            }
        },
        "dataSchema": {
            "dataSource": "ad_event_local",
            "granularitySpec": {
                "type": "uniform",
                "segmentGranularity": "day",
                "queryGranularity": "hour",
                "intervals": [
                    "2018-12-01/2018-12-03"
                ],
                "rollup": true
            },
            "parser": {
                "type": "String",
                "parseSpec": {
                    "format": "json",
                    "dimensionsSpec": {
                        "dimensions": [
                            "city",
                            "platform"
                        ]
                    },
                    "timestampSpec": {
                        "format": "auto",
                        "column": "timestamp"
                    }
                }
            },
            "metricsSpec": [
                {
                    "name": "count",
                    "type": "count"
                },
                {
                    "name": "click",
                    "type": "longSum",
                    "fieldName": "click"
                }
            ]
        },
        "tuningConfig": {
            "type": "index",
            "partitionsSpec": {
                "type": "hashed",
                "targetPartitionSize": 5000000
            }
        }
    }
}
```

提交本地批量索引任务

```
cd /export/servers/druid/quickstart/job/
curl -X 'POST' -H 'Content-Type:application/json' -d @index-local.json main1:8090/druid/indexer/v1/task
```

注意：要保证数据文件在middlemanager所在节点！

查询规则文件

```
{
    "queryType":"timeseries",
    "dataSource":"ad_event_local",
    "granularity":{"type": "period", "period": "PT1H", "timeZone": "Asia/Shanghai"},
    "aggregations":[
        {
            "type":"longSum",
            "name":"click",
            "fieldName":"click"
        },{
            "type":"longSum",
            "name":"pv",
            "fieldName":"count"
        }
    ],
    "intervals":["2018-06-02/2019-06-06"]
}
```

提交查询

```
curl -X 'POST'  -H'Content-Type: application/json'  -d @query-adtest.json http://hp103:8082/druid/v2/?pretty
```



## 1.2 以MR任务方式摄-HadoopDruidIndexer
大数据情况下跑mr不会占用druid的资源

使用HadoopDruidIndexer加载批量数据时，会启动MapReduce任务，将数据生成segments文件，存放在HDFS上，同时向Druid metastore中写入segments元数据。Coordinator Node监控元数据中有新增的segments，会将指令写入Zookeeper，而Historical Node监控到Zookeeper中的指令之后，从HDFS上下载segments文件到本地。之后，该批量数据便可从Druid中查询。

数据文件,把数据文件上传到hdfs指定路径

```
{"time":"2015-09-12T00:47:00.496Z","channel":"#ca.wikipedia","cityName":null,"comment":"Robot inserta {{Commonscat}} que enllaça amb [[commons:category:Rallicula]]","countryIsoCode":null,"countryName":null,"isAnonymous":false,"isMinor":true,"isNew":false,"isRobot":true,"isUnpatrolled":false,"metroCode":null,"namespace":"Main","page":"Rallicula","regionIsoCode":null,"regionName":null,"user":"PereBot","delta":17,"added":17,"deleted":0}
{"time":"2015-09-12T00:47:05.474Z","channel":"#en.wikipedia","cityName":"Auburn","comment":"/* Status of peremptory norms under international law */ fixed spelling of 'Wimbledon'","countryIsoCode":"AU","countryName":"Australia","isAnonymous":true,"isMinor":false,"isNew":false,"isRobot":false,"isUnpatrolled":false,"metroCode":null,"namespace":"Main","page":"Peremptory norm","regionIsoCode":"NSW","regionName":"New South Wales","user":"60.225.66.142","delta":0,"added":0,"deleted":0}
{"time":"2015-09-12T00:47:08.770Z","channel":"#vi.wikipedia","cityName":null,"comment":"fix Lỗi CS1: ngày tháng","countryIsoCode":null,"countryName":null,"isAnonymous":false,"isMinor":true,"isNew":false,"isRobot":true,"isUnpatrolled":false,"metroCode":null,"namespace":"Main","page":"Apamea abruzzorum","regionIsoCode":null,"regionName":null,"user":"Cheers!-bot","delta":18,"added":18,"deleted":0}
{"time":"2015-09-12T00:47:11.862Z","channel":"#vi.wikipedia","cityName":null,"comment":"clean up using [[Project:AWB|AWB]]","countryIsoCode":null,"countryName":null,"isAnonymous":false,"isMinor":false,"isNew":false,"isRobot":true,"isUnpatrolled":false,"metroCode":null,"namespace":"Main","page":"Atractus flammigerus","regionIsoCode":null,"regionName":null,"user":"ThitxongkhoiAWB","delta":18,"added":18,"deleted":0}
{"time":"2015-09-12T00:47:13.987Z","channel":"#vi.wikipedia","cityName":null,"comment":"clean up using [[Project:AWB|AWB]]","countryIsoCode":null,"countryName":null,"isAnonymous":false,"isMinor":false,"isNew":false,"isRobot":true,"isUnpatrolled":false,"metroCode":null,"namespace":"Main","page":"Agama mossambica","regionIsoCode":null,"regionName":null,"user":"ThitxongkhoiAWB","delta":18,"added":18,"deleted":0}
{"time":"2015-09-12T00:47:17.009Z","channel":"#ca.wikipedia","cityName":null,"comment":"/* Imperi Austrohongarès */","countryIsoCode":null,"countryName":null,"isAnonymous":false,"isMinor":false,"isNew":false,"isRobot":false,"isUnpatrolled":false,"metroCode":null,"namespace":"Main","page":"Campanya dels Balcans (1914-1918)","regionIsoCode":null,"regionName":null,"user":"Jaumellecha","delta":-20,"added":0,"deleted":20}
```



index-hadoop规则文件

```
{
    "type": "index_hadoop",
    "spec": {
        "dataSchema": {
            "dataSource": "wikiticker",
            "parser": {
                "type": "hadoopyString",
                "parseSpec": {
                    "format": "json",
                    "dimensionsSpec": {
                        "dimensions": [
                            "channel",
                            "cityName",
                            "comment",
                            "countryIsoCode",
                            "countryName",
                            "isAnonymous",
                            "isMinor",
                            "isNew",
                            "isRobot",
                            "isUnpatrolled",
                            "metroCode",
                            "namespace",
                            "page",
                            "regionIsoCode",
                            "regionName",
                            "user"
                        ]
                    },
                    "timestampSpec": {
                        "format": "auto",
                        "column": "time"
                    }
                }
            },
            "metricsSpec": [
                {
                    "name": "count",
                    "type": "count"
                },
                {
                    "name": "added",
                    "type": "longSum",
                    "fieldName": "added"
                },
                {
                    "name": "deleted",
                    "type": "longSum",
                    "fieldName": "deleted"
                },
                {
                    "name": "delta",
                    "type": "longSum",
                    "fieldName": "delta"
                }
            ],
            "granularitySpec": {
                "type": "uniform",
                "segmentGranularity": "day",
                "queryGranularity": "none",
                "intervals": [
                    "2015-09-12/2015-09-13"
                ],
                "rollup": false
            }
        },
        "ioConfig": {
            "type": "hadoop",
            "inputSpec": {
                "type": "static",
                "paths": "/wikiticker-2015-09-12-sampled.json"
            }
        },
        "tuningConfig": {
            "type": "hadoop",
            "partitionsSpec": {
                "type": "hashed",
                "targetPartitionSize": 5000000
            },
            "jobProperties": {
                "fs.default.name": "hdfs://hp101:9000",
                "fs.defaultFS": "hdfs://hp101:9000",
                "dfs.datanode.address": "hp102",
                "dfs.client.use.datanode.hostname": "true",
                "dfs.datanode.use.datanode.hostname": "true",
                "yarn.resourcemanager.hostname": "hp102",
                "yarn.nodemanager.vmem-check-enabled": "false",
                "mapreduce.map.java.opts": "-Duser.timezone=UTC -Dfile.encoding=UTF-8",
                "mapreduce.job.user.classpath.first": "true",
                "mapreduce.reduce.java.opts": "-Duser.timezone=UTC -Dfile.encoding=UTF-8",
                "mapreduce.map.memory.mb": 1024,
                "mapreduce.reduce.memory.mb": 1024
            }
        }
    },
    "hadoopDependencyCoordinates": [
        "org.apache.hadoop:hadoop-client:2.7.3"
    ]
}
```

注意：hadoopdependencyCoordinate：指定为你当前hadoop集群版本，如果与druid依赖版本不一致，需要使用命令去下载你的集群版本对应的hadoop-client.要保证数据文件存储在hdfs上并且路径正确。

提交hadoop-druid索引任务

```
curl -X 'POST' -H 'Content-Type:application/json' -d @hadoop-index.json hp101:8090/druid/indexer/v1/task
```

查询规则文件

```
{
  "queryType" : "topN",
  "dataSource" : "wikiticker",
  "intervals" : ["2015-09-12/2015-09-13"],
  "granularity" : "day",
  "dimension" : "page",
  "metric" : "edits",
  "threshold" : 25,
  "aggregations" : [
    {
      "type" : "longSum",
      "name" : "edits",
      "fieldName" : "count"
    }
  ]
}
```

提交查询任务：

```
curl -X 'POST'  -H'Content-Type: application/json'  -d @query-wikiticker.json http://hp103:8082/druid/v2/?pretty
```