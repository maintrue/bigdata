# 1 druid集群搭建

druid的分布式集群搭建，配置过程中的几个重要的点：

配置druid的deepstorage为hdfs,依赖zookeeper,元数据存储使用mysql;

coordinator,overlord:hp101;

middlemanager,historical:hp102;

broker:hp103;

重点注意内存和线程配置的时候满足druid的一个计算公式，否则可能启动没有问题但是导入数据的时候会出现错误：

| Hostname | ip            | Zookeeper  | druid节点                  | 内存 |
| -------- | ------------- | ---------- | -------------------------- | ---- |
| hp101    | 192.168.1.101 | hp101:2181 | Middlemanager,historical   | 3g   |
| hp102    | 192.168.1.102 | hp102:2181 | Coordinator,overlord,mysql | 3g   |
| hp103    | 192.168.1.103 | hp103:2181 | Broker                     | 3g   |

解压druid安装包到/export/servers/目录下

```
tar -zxvf druid-0.10.1-bin.tar.gz -C /export/servers/
```

```
cd /export/servers/druid-0.10.1
```

## 1.1 公共配置

公共配置在conf/druid/_common,我们需要编辑common.runtime.properties文件 ，下面主要是我们修改的重要配置，其它配置保留默认即可：

（1）配置两个启动加载的扩展。一个是HDFS存储，一个是MySQL元数据 

```
druid.extensions.loadList=["druid-hdfs-storage","mysql-metadata-storage"]
```

注意扩展依赖需要下载：

```
java -classpath "lib/*" io.druid.cli.Main tools pull-deps --defaultVersion 0.10.1 -c io.druid.extensions:mysql-metadata-storage:0.10.1 -c druid-hdfs-storage -h org.apache.hadoop:hadoop-client:2.7.3
```



（2）配置Zookeeper地址

```
druid.zk.service.host=hp101:2181,hp102:2181,hp103:2181
druid.zk.paths.base=/druid
```

（3）配置 Metastore存储信息

```
druid.metadata.storage.type=mysql
druid.metadata.storage.connector.connectURI=jdbc:mysql://hp102:3306/druid
druid.metadata.storage.connector.user=root
druid.metadata.storage.connector.password=000000

```

 注意：mysql需要提前安装好，并且数据库druid要提前创建好并且指定utf-8编码；

（4）配置底层存储。路径是HDFS路径 

```
druid.storage.type=hdfs
druid.storage.storageDirectory=/druid/segments
```

（5）配置indexingservice服务的日志存储路径，路径是HDFS路径。

```
druid.indexer.logs.type=hdfs
druid.indexer.logs.directory=/druid/indexing-logs
```

(6)因为我们会使用到hdfs作为底层存储所以我们需要告知druid hadoop集群的相关信息，所以我们需要把hadoop相关的配置文件复制到conf/druid/_common/目录中；

hdfs-site.xml，core-site.xml，mapred-site.xml，yarn-site.xml四个配置文件 。

```
[root@hp101 _common]#ln -s /export/servers/hadoop-2.7.2/etc/hadoop/core-site.xml ./core-site.xml
[root@hp101 _common]#ln -s /export/servers/hadoop-2.7.2/etc/hadoop/mapred-site.xml.template ./mapred-site.xml
[root@hp101 _common]# ln -s /export/servers/hadoop-2.7.2/etc/hadoop/yarn-site.xml ./yarn-site.xml
[root@hp101 _common]# ln -s /export/servers/hadoop-2.7.2/etc/hadoop/hdfs-site.xml ./hdfs-site.xml
```



common.runtime.properties完整配置

```

druid.extensions.loadList=["druid-hdfs-storage","mysql-metadata-storage"]


# Log all runtime properties on startup. Disable to avoid logging properties on startup:
druid.startup.logging.logProperties=true

#
# Zookeeper
#

druid.zk.service.host=hp101:2181,hp102:2181,hp103:2181
druid.zk.paths.base=/druid

#
# Metadata storage

# For MySQL:
druid.metadata.storage.type=mysql
druid.metadata.storage.connector.connectURI=jdbc:mysql://hp102:3306/druid
druid.metadata.storage.connector.user=root
druid.metadata.storage.connector.password=000000


#
# Deep storage


# For HDFS (make sure to include the HDFS extension and that your Hadoop config files in the cp):
druid.storage.type=hdfs
druid.storage.storageDirectory=/druid/segments

#
# Indexing service logs
#

# For HDFS (make sure to include the HDFS extension and that your Hadoop config files in the cp):
druid.indexer.logs.type=hdfs
druid.indexer.logs.directory=/druid/indexing-logs

#
# Service discovery
#

druid.selectors.indexing.serviceName=druid/overlord
druid.selectors.coordinator.serviceName=druid/coordinator

#
# Monitoring
#

druid.monitoring.monitors=["com.metamx.metrics.JvmMonitor"]
druid.emitter=logging
druid.emitter.logging.logLevel=info

```



## 1.2 historical配置

配置文件在conf/druid/historical，先配置jvm.config，再配置runtime.properties 

（1）jvm.config 

```
vim historical/jvm.config
```

```
-server
-Xms1g
-Xmx3g
-XX:MaxDirectMemorySize=2048m
-Duser.timezone=UTC+8
-Dfile.encoding=UTF-8
-Djava.io.tmpdir=var/tmp
-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager
```

注意1：以上每一行都是JVM参数，保持原样一个配置占用一行。java.io.tmpdir路径需要我们手动创建出来。

关于内存配置。这个关乎该节点是否能正常运行。-Xms，初始堆内存大小，设置了1g，-Xmx，最大堆内存大小，设置了3g。 此外java.io.tmpdir路径需要手动创建

注意2：关于-XX:MaxDirectoryMemortySize,这个配置需要重点关注：直接内存--》堆外内存；

该参数的大小要满足一个公式：

druid.processing.buffer.sizeBytes*(druid.processing.numThreads+1+druid.processing.numMergeBuffers) <= MaxDirectMemorySize ;以上几个参数是在下面的runtime.properties中，druid.processing.numMergeBuffers默认等于2

maxDirectMemorySize<-Xmx（最大堆内存）

runtime.properties配置

```
druid.service=druid/historical
druid.port=8083

# HTTP server threads
druid.server.http.numThreads=3

# Processing threads and buffers
druid.processing.buffer.sizeBytes=536870912
druid.processing.numThreads=1

# Segment storage
druid.segmentCache.locations=[{"path":"/export/servers/druid010/var/druid/segment-cache","maxSize"\:130000000000}]
druid.server.maxSize=130000000000
```

## 1.3 middleManager的配置

配置文件在conf/druid/middleManager/路径下，两个配置文件 

1 jvm.config

```
-server
-Xms64m
-Xmx64m
-Duser.timezone=UTC+8
-Dfile.encoding=UTF-8
-Djava.io.tmpdir=var/tmp
-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager
```

runtime.properties

```
druid.service=druid/middleManager
druid.port=8091

# Number of tasks per middleManager
druid.worker.capacity=3

# Task launch parameters
druid.indexer.runner.javaOpts=-server -Xmx3g -Duser.timezone=UTC+8 -Dfile.encoding=UTF-8 -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager

druid.indexer.task.baseTaskDir=var/druid/task

# HTTP server threads
druid.server.http.numThreads=3

# Processing threads and buffers on Peons
druid.indexer.fork.property.druid.processing.buffer.sizeBytes=506870912
druid.indexer.fork.property.druid.processing.numThreads=1

# Hadoop indexing
druid.indexer.task.hadoopWorkingPath=var/druid/hadoop-tmp
druid.indexer.task.defaultHadoopCoordinates=["org.apache.hadoop:hadoop-client:2.7.3"]
```

task launch参数，是创建indexer task时所配置的虚拟机参数。indexer task很像MapReduce的task，每个任务都会产生一个虚拟机。Druid强大之处也是实现了自己的分布式计算框架。大部分配置都可以不用修改。为避免兼容性问题，确保hadoop indexing部分的依赖配置版本。这里我们用的hadoop-client是2.7.3

## 1.4 broker配置

jvm.config

```
-server
-Xms2g
-Xmx3g
-XX:MaxDirectMemorySize=2048m
-Duser.timezone=UTC+8
-Dfile.encoding=UTF-8
-Djava.io.tmpdir=var/druid-data/tmpdir
-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager
```

runtime.properties

```
druid.service=druid/broker
druid.port=8082

# HTTP server threads
druid.broker.http.numConnections=5
druid.server.http.numThreads=3

# Processing threads and buffers
druid.processing.buffer.sizeBytes=322122574
druid.processing.numThreads=1

# Query cache
druid.broker.cache.useCache=true
druid.broker.cache.populateCache=true
druid.cache.type=local
druid.cache.sizeInBytes=2000000000
```

## 1.5 coordinator配置

jvm.config

```
-server
-Xms1g
-Xmx2g
-Duser.timezone=UTC+8
-Dfile.encoding=UTF-8
-Djava.io.tmpdir=var/tmp
-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager
-Dderby.stream.error.file=var/druid/derby.log
```

runtime.properties

```
druid.service=druid/coordinator
druid.port=8081

druid.coordinator.startDelay=PT30S
druid.coordinator.period=PT30S
```



## 1.6 overlord配置

jvm.config

```
-server
-Xms1g
-Xmx1g
-Duser.timezone=UTC+8
-Dfile.encoding=UTF-8
-Djava.io.tmpdir=var/tmp
-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager
```

runtime.properties

```
druid.service=druid/overlord
druid.port=8090

druid.indexer.queue.startDelay=PT30S

druid.indexer.runner.type=remote
druid.indexer.storage.type=metadata

```

注意：以上是druid的配置信息，此外不要忘记启动mysql(在conf/druid/_common/common.properties中所配置)，需要提前创建druid数据库。

## 7 启动druid集群

```
# 在hp103启动broker
nohup bin/broker.sh start >log/broker.log 2>&1 &

# 在hp102启动historical
nohup bin/historical.sh start >log/historical.log 2>&1 &

# 在hp102启动middleManager
nohup bin/middlemanager.sh start >log/middlemanager.log 2>&1 &

# 在hp101启动coordinator
nohup bin/coordinator.sh start >log/coordinator.log 2>&1 &

# 在hp101启动overlord
nohup bin/overlord.sh start >log/overlord.log 2>&1 &


```

web界面访问：

hp101:8081 coordinator

hp101:8090 overlord

页面正常访问则证明集群搭建成功否则查看启动日志报错信息，日志目录：druid010/log/...

常用端口补充：

8081 (Coordinator)
8082 (Broker)
8083 (Historical)
8084 (Standalone Realtime, 我们没有使用,已经被弃用)
8088 (Router, 我们没有使用,broker的一个网关，实现请求负载均衡到broker节点)
8090 (Overlord)
8091 (Druid Middle Manager)

8100–8199 这些端口号是middleManager开启作业时各个作业自己的端口号