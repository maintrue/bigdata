# 1 Streaming File Sink

## 1.1 介绍
https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/streamfile_sink.html

https://blog.csdn.net/u013220482/article/details/100901471

### 1.1.1 场景描述
StreamingFileSink是Flink1.7中推出的新特性，是为了解决如下的问题：

大数据业务场景中，经常有一种场景：外部数据发送到kafka中，flink作为中间件消费kafka数据并进行业务处理；处理完成之后的数据可能还需要写入到数据库或者文件系统中，比如写入hdfs中。

StreamingFileSink就可以用来将分区文件写入到支持 Flink FileSystem 接口的文件系统中，支持Exactly-Once语义。

这种sink实现的Exactly-Once都是基于Flink checkpoint来实现的两阶段提交模式来保证的，主要应用在实时数仓、topic拆分、基于小时分析处理等场景下。

### 1.1.2 Bucket和SubTask、PartFile
1.Bucket
- StreamingFileSink可向由Flink FileSystem抽象支持的文件系统写入分区文件（因为是流式写入，数据被视为无界）。该分区行为可配，默认按时间，具体来说每小时写入一个Bucket，该Bucket包括若干文件，内容是这一小时间隔内流中收到的所有record。

2.PartFile
- 每个Bukcket内部分为多个PartFile来存储输出数据，该Bucket生命周期内接收到数据的sink的每个子任务至少有一个PartFile。
- 而额外文件滚动由可配的滚动策略决定，默认策略是根据文件大小和打开超时（文件可以被打开的最大持续时间）以及文件最大不活动超时等决定是否滚动。
- Bucket和SubTask、PartFile关系如图所示

## 1.2 案例演示

### 1.2.1 需求
编写Flink程序，接收socket的字符串数据，然后将接收到的数据流式方式存储到hdfs

### 1.2.2 开发步骤
1. 初始化流计算运行环境
2. 设置Checkpoint（10s）周期性启动
3. 指定并行度为1
4. 接入socket数据源，获取数据
5. 指定文件编码格式为行编码格式
6. 设置桶分配策略
7. 设置文件滚动策略
8. 指定文件输出配置
9. 将streamingfilesink对象添加到环境
10. 执行任务

### 1.2.3 实现代码
package com.main.bd.flink.sink;