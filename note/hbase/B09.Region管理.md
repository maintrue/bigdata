# 1 Region管理

## 1.1 region分配
任何时刻，一个region只能分配给一个region server

Master记录了当前有哪些可用的region server，以及当前哪些region分配给了哪些region server，哪些region还没有分配。当需要分配的新的region，并且有一个region server上有可用空间时，master就给这个region server发送一个装载请求，把region分配给这个region server。region server得到请求后，就开始对此region提供服务。

## 1.2 region server上线
Master使用ZooKeeper来跟踪region server状态

当某个region server启动时
- 首先在zookeeper上的server目录下建立代表自己的znode
- 由于Master订阅了server目录上的变更消息，当server目录下的文件出现新增或删除操作时，master可以得到来自zookeeper的实时通知
- 一旦region server上线，master能马上得到消息。

## 1.3 region server下线
当region server下线时，它和zookeeper的会话断开，ZooKeeper而自动释放代表这台server的文件上的独占锁

Master就可以确定
- region server和zookeeper之间的网络断开了
- region server挂了

无论哪种情况，region server都无法继续为它的region提供服务了，此时master会删除server目录下代表这台region server的znode数据，并将这台region server的region分配给其它还活着的节点

## 1.4 Region分裂
当region中的数据逐渐变大之后，达到某一个阈值，会进行裂变
- 一个region等分为两个region，并分配到不同的RegionServer
- 原本的Region会下线，新Split出来的两个Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上。

``` 
<-- Region最大文件大小为10G -->
<property>
    <name>hbase.hregion.max.filesize</name>
    <value>10737418240</value>
    <final>false</final>
    <source>hbase-default.xml</source>
</property>
```

HBase只是增加数据，所有的更新和删除操作，都是在Compact阶段做的

用户写操作只需要进入到内存即可立即返回，从而保证I/O高性能读写

### 1.4.1 自动分区
之前，我们在建表的时候，没有涉及过任何关于Region的设置，由HBase来自动进行分区。也就是Region达到一定大小就会自动进行分区。最小的分裂大小和table的某个region server的region 个数有关，当store file的大小大于如下公式得出的值的时候就会split，公式如下:
``` 
Min (R^2 * “hbase.hregion.memstore.flush.size”, “hbase.hregion.max.filesize”) 
```
R为同一个table中在同一个region server中region的个数。

如果初始时R=1,那么Min(128MB,10GB)=128MB,也就是说在第一个flush的时候就会触发分裂操作

当R=2的时候Min(22128MB,10GB)=512MB ,当某个store file大小达到512MB的时候，就会触发分裂

如此类推，当R=9的时候，store file 达到10GB的时候就会分裂，也就是说当R>=9的时候，store file 达到10GB的时候就会分裂

split 点都位于region中row key的中间点

### 1.4.2 手动分区
在创建表的时候，就可以指定表分为多少个Region。默认一开始的时候系统会只向一个RegionServer写数据，系统不指定startRow和endRow，可以在运行的时候提前Split，提高并发写入。

