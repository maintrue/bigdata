# 1 HDFS文件限额配置
在多人共用HDFS的环境下，配置设置非常重要。特别是在Hadoop处理大量资料的环境，如果没有配额管理，很容易把所有的空间用完造成别人无法存取。___hdfs的配额设定是针对目录而不是针对账号___，可以让每个账号仅操作某一个目录，然后对目录设置配置。

hdfs文件的限额配置允许我们以文件个数，或者文件大小来限制我们在某个目录下上传的文件数量或者文件内容总量，以便达到我们类似百度网盘网盘等限制每个用户允许上传的最大的文件的量。

查看配额信息:
``` 
hdfs dfs -count -q -h /a/b/c
```

## 1.1 数量限额
创建hdfs文件夹
```hdfs dfs -mkdir -p /user/root/dir```

给该文件夹下面设置最多上传两个文件，发现只能上传一个文件
```hdfs dfsadmin -setQuota 2 dir```

清除文件数量限制
```
hdfs dfsadmin -clrQuota /user/root/dir
```

## 1.2 空间大小限额
在设置空间配额时，设置的空间至少是block_size * 3大小

限制空间大小4KB
```
hdfs dfsadmin -setSpaceQuota 4k /user/root/dir
```

尝试上传文件
```
hdfs dfs -put /root/a.txt /user/root/dir
```

生成任意大小文件的命令:
```
生成2M的文件
dd if=/dev/zero of=1.txt bs=1M count=2
```

清除空间配额限制
``` 
hdfs dfsadmin -clrSpaceQuota /user/root/dir
```

# 2 hdfs的安全模式
安全模式是hadoop的一种保护机制，用于保证集群中的数据块的安全性。当集群启动的时候，会首先进入安全模式。当系统处于安全模式时会检查数据块的完整性。

假设我们设置的副本数（即参数dfs.replication）是3，那么在datanode上就应该有3个副本存在，假设只存在2个副本，那么比例就是2/3=0.666。

hdfs默认的副本率0.999。我们的副本率0.666明显小于0.999，因此系统会自动的复制副本到其他dataNode，使得副本率不小于0.999。如果系统中有5个副本，超过我们设定的3个副本，那么系统也会删除多于的2个副本。

在安全模式状态下，文件系统只接受读数据请求，而不接受删除、修改等变更请求。在，当整个系统达到安全标准时，HDFS自动离开安全模式。

## 2.1 安全模式操作命令
查看安全模式状态
```
hdfs dfsadmin -safemode get
```

进入安全模式
```
hdfs dfsadmin -safemode enter
```
离开安全模式
```
hdfs dfsadmin -safemode leave
```

# 3 HDFS基准测试
实际生产环境当中，hadoop的环境搭建完成之后，第一件事情就是进行压力测试，测试我们的集群的读取和写入速度，测试我们的网络带宽是否足够等一些基准测试

## 3.1 测试写入速度
向HDFS文件系统中写入数据,10个文件,每个文件10MB,文件存放到/benchmarks/TestDFSIO中
``` 
hadoop jar /export/servers/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5.jar TestDFSIO -write -nrFiles 10 -fileSize 10MB
```
完成之后查看写入速度结果
``` 
hdfs dfs -text /benchmarks/TestDFSIO/io_write/part-00000
```

测试结果
- 含有文件数量为10，总大小为10MB，每秒平均写入速度为28.22MB，执行花费时间为9.51s

![image](https://user-images.githubusercontent.com/75486726/178136007-76021c2b-3d25-4e3e-8cf0-37ca6757cfef.png)

## 3.2 测试读取速度
在HDFS文件系统中读入10个文件,每个文件10M
``` 
hadoop jar /export/servers/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5.jar TestDFSIO -read -nrFiles 10 -fileSize 10MB
```

查看读取果
``` 
hdfs dfs -text /benchmarks/TestDFSIO/io_read/part-00000
```

测试结果
- 每秒平均读速度为1605.16MB，总共花费2.63秒

![image](https://user-images.githubusercontent.com/75486726/178136019-2d800055-1492-467f-8590-dd69fcf40cda.png)

## 3.3 清除测试数据
``` 
hadoop jar /export/servers/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5.jar TestDFSIO -clean
```
