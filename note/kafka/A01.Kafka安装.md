# 1 环境搭建
本次课程使用的Kafka版本为2.4.1，是2020年3月12日发布的版本。

可以注意到Kafka的版本号为：kafka_2.12-2.4.1，因为kafka主要是使用scala语言开发的，2.12为scala的版本号。http://kafka.apache.org/downloads可以查看到每个版本的发布时间

## 1.1 搭建Kafka集群
1.将Kafka的安装包上传到虚拟机，并解压
``` 
tar -xvzf kafka_2.12-2.4.1.tgz -C /export/servers/
```

2.修改 server.properties
``` 
cd /export/server/kafka_2.12-2.4.1/config
vi server.properties
# 指定broker的id
broker.id=0
# 指定Kafka数据的位置
log.dirs=/export/servers/kafka_2.12-2.4.1/data
# 配置zk的三个节点
zookeeper.connect=node1.itcast.cn:2181,node2.itcast.cn:2181,node3.itcast.cn:2181
```

3.将安装好的kafka复制到另外两台服务器
``` 
cd /export/servers
scp -r kafka_2.12-2.4.1/ node2.itcast.cn:$PWD
scp -r kafka_2.12-2.4.1/ node3.itcast.cn:$PWD

修改另外两个节点的broker.id分别为1和2
---------node2.itcast.cn--------------
cd /export/server/kafka_2.12-2.4.1/config
vim erver.properties
broker.id=1

--------node3.itcast.cn--------------
cd /export/server/kafka_2.12-2.4.1/config
vi server.properties
broker.id=2
```

4.配置KAFKA_HOME环境变量
``` 
vi /etc/profile
export KAFKA_HOME=/export/servers/kafka_2.12-2.4.1
export PATH=:$PATH:${KAFKA_HOME}

分发到各个节点
scp /etc/profile node2.itcast.cn:$PWD
scp /etc/profile node3.itcast.cn:$PWD
每个节点加载环境变量
source /etc/profile
```

5.启动服务器
``` 
# 启动ZooKeeper
nohup bin/zookeeper-server-start.sh config/zookeeper.properties &
# 启动Kafka
cd /export/server/kafka_2.12-2.4.1
nohup bin/kafka-server-start.sh config/server.properties &
# 测试Kafka集群是否启动成功
bin/kafka-topics.sh --bootstrap-server node1.itcast.cn:9092 --list
```

## 1.2 目录结构分析
| 目录名称    | 说明
| --- | ---
| bin | Kafka的所有执行脚本都在这里。例如：启动Kafka服务器、创建Topic、生产者、消费者程序等等
| config  | Kafka的所有配置文件
| libs    | 运行Kafka所需要的所有JAR包
| logs    | Kafka的所有日志文件，如果Kafka出现一些问题，需要到该目录中去查看异常信息
| site-docs   | Kafka的网站帮助文件

## 1.3  Kafka一键启动/关闭脚本
为了方便将来进行一键启动、关闭Kafka，我们可以编写一个shell脚本来操作。将来只要执行一次该脚本就可以快速启动/关闭Kafka。

1.在节点1中创建 /export/onekey 目录
``` 
mkdir /export/onekey
cd /export/onekey
```

2.准备slave配置文件，用于保存要启动哪几个节点上的kafka
``` 
vi kafka_slave

node1.itcast.cn
node2.itcast.cn
node3.itcast.cn
```


3.编写start-kafka.sh脚本
``` 
vi start-kafka.sh
#!/bin/sh
cat /export/onekey/kafka_slave | while read line
do
{
    echo $line
    ssh $line "source /etc/profile;export JMX_PORT=9988;nohup ${KAFKA_HOME}/bin/kafka-server-start.sh ${KAFKA_HOME}/config/server.properties >/dev/nul* 2>&1 & "
}&
wait
done
```

4.编写stop-kafka.sh脚本
``` 
vi stop-kafka.sh
#!/bin/sh
cat /export/onekey/kafka_slave | while read line
do
{
    echo $line
    ssh $line "source /etc/profile;jps |grep Kafka |cut -d' ' -f1 |xargs kill -s 9"
}&
wait
done
```


5.给start-kafka.sh、stop-kafka.sh配置执行权限
``` 
chmod u+x start-kafka.sh
chmod u+x stop-kafka.sh
```

6. 执行一键启动、一键关闭
``` 
./start-kafka.sh
./stop-kafka.sh
```

## 1.4 Kafka配置文件
``` 
#broker的全局唯一编号，不能重复
broker.id=0
#是否允许删除topic
delete.topic.enable=true
#处理网络请求的线程数量
num.network.threads=3
#用来处理磁盘IO的线程数量
num.io.threads=8
#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400
#接收套接字的缓冲区大小
socket.receive.buffer.bytes=102400
#请求套接字的最大缓冲区大小
socket.request.max.bytes=104857600
#kafka运行日志存放的路径
log.dirs=/opt/module/kafka/logs
#topic在当前broker上的分区个数
num.partitions=1
#用来恢复和清理data下数据的线程数量
num.recovery.threads.per.data.dir=1
#segment文件保留的最长时间，超时将被删除
log.retention.hours=168
#配置连接Zookeeper集群地址
zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181
```

