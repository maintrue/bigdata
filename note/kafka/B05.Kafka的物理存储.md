# 1 Kafka的数据存储形式
一个topic由多个分区组成

一个分区（partition）由多个segment（段）组成

一个segment（段）由多个文件组成（log、index、timeindex）

## 1.1 存储日志
接下来，我们来看一下Kafka中的数据到底是如何在磁盘中存储的。

Kafka中的数据是保存在 /export/server/kafka_2.12-2.4.1/data中

消息是保存在以：「主题名-分区ID」的文件夹中的

数据文件夹中包含以下内容：

这些分别对应：

| 文件名 | 说明  
| --- | ---
| 00000000000000000000.index  | 索引文件，根据offset查找数据就是通过该索引文件来操作的
| 00000000000000000000.log    | 日志数据文件
| 00000000000000000000.timeindex  | 时间索引
| leader-epoch-checkpoint | 持久化每个partition leader对应的LEO（log end offset、日志文件中下一条待写入消息的offset）

每个日志文件的文件名为起始偏移量，因为每个分区的起始偏移量是0，所以，分区的日志文件都以0000000000000000000.log开始

默认的每个日志文件最大为「log.segment.bytes =1024*1024*1024」1G

为了简化根据offset查找消息，Kafka日志文件名设计为开始的偏移量

## 1.2 观察测试
为了方便测试观察，新创建一个topic：「test_10m」，该topic每个日志数据文件最大为10M
``` 
bin/kafka-topics.sh --create --zookeeper node1.itcast.cn --topic test_10m --replication-factor 2 --partitions 3 --config segment.bytes=10485760
```
使用之前的生产者程序往「test_10m」主题中生产数据，可以观察到如下：

## 1.3 存储策略
无论消息是否被消费，kafka都会保留所有消息。有两种策略可以删除旧数据：
1. 基于时间：log.retention.hours=168
2. 基于大小：log.retention.bytes=1073741824

需要注意的是，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高 Kafka 性能无关。

## 1.4 写入消息
新的消息总是写入到最后的一个日志文件中

该文件如果到达指定的大小（默认为：1GB）时，将滚动到一个新的文件中

## 1.5 读取消息
根据「offset」首先需要找到存储数据的 segment 段（注意：offset指定分区的全局偏移量）

然后根据这个「全局分区offset」找到相对于文件的「segment段offset」

最后再根据 「segment段offset」读取消息

为了提高查询效率，每个文件都会维护对应的范围内存，查找的时候就是使用简单的二分查找

## 1.6 删除消息
在Kafka中，消息是会被定期清理的。一次删除一个segment段的日志文件

Kafka的日志管理器，会根据Kafka的配置，来决定哪些文件可以被删除

## 1.7 Zookeeper存储结构
ZK用来管理和协调broker，并且存储了Kafka的元数据（例如：有多少topic、partition、consumer）

ZK服务主要用于通知生产者和消费者Kafka集群中有新的broker加入、或者Kafka集群中出现故障的broker。

PS：Kafka正在逐步想办法将ZooKeeper剥离，维护两套集群成本较高，社区提出KIP-500就是要替换掉ZooKeeper的依赖。“Kafka on Kafka”——Kafka自己来管理自己的元数据

注意：producer不在zk中注册，消费者在zk中注册。